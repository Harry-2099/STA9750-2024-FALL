[
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Harry’s Mental Health Study",
    "section": "Introduction",
    "text": "Introduction\nHello, I’m Harry and welcome to my first github pages website. I promise I’m not insane I just wanted to graph something and went with this is corny joke. I am in a MS in Statistics and Data Science program, coming from a business background. My decision to pursue this degree stemmed from my desire to learn the intricacies involved in modern stats and their applications.Topics that particularly excite me are Machine and Statistical Learning as well as the application of these to financial and economic problems."
  },
  {
    "objectID": "mp01.html",
    "href": "mp01.html",
    "title": "Mini Project 1",
    "section": "",
    "text": "This analysis looks to provide some insights on the financial information behind some of the biggest transit agencies in the US. The data set being studied includes massive systems like the NYC Metro and also lesser used systems in states like Hawaii and Oklahoma.\n\n\n\nAfter loading the data certain column names and row values need to be changed for syntactic reasons and ease of understanding. Firstly, changing the column UZA Name to metro_area will allow for syntactic ease, and a more intuitive label.\n\nUSAGE &lt;- inner_join(TRIPS, MILES) |&gt;\n    mutate(`NTD ID` = as.integer(`NTD ID`))\n\nJoining with `by = join_by(`NTD ID`, Agency, `UZA Name`, Mode, `3 Mode`,\nmonth)`\n\n    sample_n(USAGE, 1000) |&gt; \n    rename(\"metro_area\" = \"UZA Name\") %&gt;% #renaming UZA\n    mutate(month=as.character(month))\n\n# A tibble: 1,000 × 8\n   `NTD ID` Agency                 metro_area Mode  `3 Mode` month    UPT    VRM\n      &lt;int&gt; &lt;chr&gt;                  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1    20113 Regional Transit Serv… Rochester… MB    Bus      2016… 1.33e6 417338\n 2    50019 City of Middletown     Middletow… DR    Bus      2008… 7.18e2   4172\n 3    30111 Washington County Tra… Pittsburg… MB    Bus      2014… 1.53e3   6581\n 4    20018 Central New York Regi… Syracuse,… DR    Bus      2019… 6.92e3 100968\n 5    60102 Concho Valley Transit… San Angel… MB    Bus      2008… 1.65e4  32176\n 6    50166 Clermont County, Ohio  Cincinnat… MB    Bus      2020… 7.2 e2   8974\n 7    50113 Pace, the Suburban Bu… Chicago, … VP    Bus      2011… 1.47e5 795247\n 8    40093 City of Greensboro     Greensbor… MB    Bus      2011… 3.34e5 164105\n 9    20004 Niagara Frontier Tran… Buffalo, … MB    Bus      2017… 1.73e6 665018\n10        7 Lane Transit District  Eugene, OR MB    Bus      2020… 1.15e3 124987\n# ℹ 990 more rows\n\n\nThe second section will be “re-coding” the Mode date in the dataframe. Since the data originally had codes like “HR” for Heavy Rail, or “FB” for Ferry Boat it will be hard for someone ignorant of these codes to understand the meaning behind them. So we will find all the distinct values, search their meanings, and then rename those values. The results will be displayed a Data Table using the DT library\n\n  distinct_modes&lt;- USAGE %&gt;% distinct(Mode)\n \n   USAGE &lt;- USAGE |&gt;\n     mutate(Mode=case_when(\n          Mode == \"HR\" ~ \"Heavy Rail\", \n          Mode == \"DR\"~\"Demand Response\",\n          Mode == \"FB\"~\"Ferryboat\",\n          Mode == \"MB\"~\"Bus\",\n          Mode == \"SR\"~\"Streetcar Rail\",\n          Mode == \"TB\"~\"Trolleybus\",\n          Mode == \"VP\"~\"Vanpool\",\n          Mode == \"CB\"~\"Commuter Bus\",\n          Mode == \"RB\"~\"Bus Rapid Transit\",\n          Mode == \"LR\"~\"Light Rail\",\n          Mode == \"YR\"~\"Hybrid Rail\",\n          Mode == \"MG\"~\"Monorail Automated Guideway\",\n          Mode == \"CR\"~\"Commuter Rail\",\n          Mode == \"AR\"~\"Alaska Railroad\",\n          Mode == \"TR\"~\"Aerial Tramway\",\n          Mode == \"IP\"~\"Inclined Plane\",\n          Mode == \"PB\"~\"Publico\",\n          Mode == \"CC\"~\"Cable Car\",\n          TRUE~\"Unknown\"))\n    Use_table &lt;- DT::datatable(head(USAGE, 5000))\n\n\n\n\n\n\n\n\n\n\n\n\nUsing the arrange function we can sort the data based on a ascending or descending order of a specified value. Using arrange combined with desc function we get the all the VRM values starting from highest to lowest. The corresponding agency will be the answer.\n\nMax_VRM &lt;- USAGE %&gt;% \n    select(VRM,Agency) %&gt;%\n    arrange(desc(VRM)) %&gt;% \n    head(1)\n    print(Max_VRM)\n\n# A tibble: 1 × 2\n       VRM Agency                   \n     &lt;dbl&gt; &lt;chr&gt;                    \n1 30882144 MTA New York City Transit\n\n\n\n\n\nUsing the same idea as the previous question, this time combining it with the group_by function will allow us to find the answer. The group_by function creates “groups” of a given variable to then perform some action to those groups. In this case we will group by the mode and then sum up the VRM for each mode. This method will provide the answer “Bus”\n\nvrm_by_mode &lt;- USAGE %&gt;% \n    select(VRM,Mode) %&gt;%\n    group_by(Mode) %&gt;% \n    summarise(Total = sum(VRM)) %&gt;% \n    arrange(desc(Total))\n    print(vrm_by_mode)\n\n# A tibble: 18 × 2\n   Mode                              Total\n   &lt;chr&gt;                             &lt;dbl&gt;\n 1 Bus                         49444494088\n 2 Demand Response             17955073508\n 3 Heavy Rail                  14620362107\n 4 Commuter Rail                6970644241\n 5 Vanpool                      3015783362\n 6 Light Rail                   2090094714\n 7 Commuter Bus                 1380948975\n 8 Publico                      1021270808\n 9 Trolleybus                    236840288\n10 Bus Rapid Transit             118425283\n11 Ferryboat                      65589783\n12 Streetcar Rail                 63389725\n13 Monorail Automated Guideway    37879729\n14 Hybrid Rail                    37787608\n15 Alaska Railroad                13833261\n16 Cable Car                       7386019\n17 Inclined Plane                   705904\n18 Aerial Tramway                   292860\n\n\n\n\n\nTo answer this the use of the filter function is required. The filter function will remove all the data that doesn’t agree with the filter statement, allowing for more specific analysis. Filtering for a May 2024 date and a NYC MTA Agency Subway will give the answer, but first some data manipulating is required. Creating a year and month column with the lubridate library, allows for quick and easy date time analysis and will come in handy, making future analysis streamlined. After doing so the previous techniques are used.\n\n  typeof(USAGE$month)#checking the type of column month is\n\n[1] \"double\"\n\nlibrary(lubridate)\n  USAGE$month &lt;- ymd(USAGE$month) #changing to date format\n  USAGE &lt;- USAGE %&gt;% \n     rename(\"trips\"=UPT) %&gt;% #renaming the UPT(Unlinked passenger trips)- to trips\n     rename(\"date\"=month) %&gt;%  \n     mutate(\"year\"= year(date)) %&gt;%\n     mutate('month'= month(date))\n  nyc_trips &lt;- USAGE %&gt;% \n    filter(Agency == \"MTA New York City Transit\" & Mode ==\"Heavy Rail\")%&gt;% \n    filter(year==2024 & month == 5) %&gt;% \n    summarise(may_total=sum(trips))\n    print(nyc_trips)\n\n# A tibble: 1 × 1\n  may_total\n      &lt;dbl&gt;\n1 180458819\n\n\n\n\n\nUsing all the techniques from the previous questions, along with the pull method to give a singular value will provide an answer for this question. After pulling the data for both cases we can simply find the difference.\n\n  nyc_monthly &lt;- USAGE %&gt;% #this table provides info that might be useful later on\n    filter(Agency == 'MTA New York City Transit' & Mode == 'Heavy Rail') %&gt;% \n    group_by(year, month) %&gt;%                       \n    mutate(total_vrm = sum(VRM)) %&gt;% \n    mutate(total_trips = sum(trips)) %&gt;%\n    select(year,month,total_trips,total_vrm)\n   vrm_2019 &lt;- nyc_monthly %&gt;%\n    filter(year == 2019 & month == 4) %&gt;% \n    pull(total_vrm)\n  \n  vrm_2020 &lt;- nyc_monthly %&gt;%\n    filter(year == 2020 & month == 4) %&gt;% \n    pull(total_vrm)\n  \n  print(\"VRM Difference\")\n\n[1] \"VRM Difference\"\n\n  vrm_2019-vrm_2020 #difference in Vehicle Revenue Miles\n\n[1] 12200677\n\n  trips_2019 &lt;- nyc_monthly %&gt;%\n    filter(year == 2019 & month == 4) %&gt;% \n    pull(total_trips)\n  \n  trips_2020 &lt;- nyc_monthly %&gt;%\n    filter(year == 2020 & month == 4) %&gt;% \n    pull(total_trips)\n  print(\"Trips Difference\")\n\n[1] \"Trips Difference\"\n\n  trips_2019-trips_2020 #decrease in trips\n\n[1] 211969660\n\n\n\n\n\n\n\nUsing a combintion of techniques like filtering, summarize, as well as grouping by the month column will provide the answer.\n\n     USAGE %&gt;% \n     filter(year == 2023) %&gt;% \n     select(year,month,VRM) %&gt;% \n     group_by(month) %&gt;% \n     summarise(total_vrm = sum(VRM)) %&gt;% \n     arrange(desc(total_vrm))\n\n# A tibble: 12 × 2\n   month total_vrm\n   &lt;dbl&gt;     &lt;dbl&gt;\n 1     8 422002435\n 2    10 420684229\n 3     3 413311032\n 4     5 407605645\n 5    11 402542477\n 6     6 400875583\n 7    12 399428041\n 8     7 398685473\n 9     9 398172153\n10     1 389141732\n11     4 386876164\n12     2 361882307\n\n\n\n\n\nSimilarly with this question grouping by year and computing the desired value, using mutate this time, gives us the answer. We can also plot this to see some yearly trends using ggplot.\n\n  yearly_trips &lt;- USAGE %&gt;% \n     group_by(year) %&gt;% \n     mutate(total_trips = sum(trips)) %&gt;%\n     mutate(avg_trip_day = total_trips/365) %&gt;% \n     select(year,total_trips,avg_trip_day) %&gt;% \n     arrange(desc(total_trips)) %&gt;% \n     distinct(year,total_trips,avg_trip_day)\n     #plotting\n     ggplot(yearly_trips,aes(x= year,y=avg_trip_day))+\n       geom_line(color = 'blue')+\n       labs(title = \"Trends in Avg Trips Per Day\", y = \"Unlinked Trips\",x = \"Years\")+\n       theme_minimal()\n\n\n\n\n\n\n\n\nPredictably, there is a huge drop in 2020 in average trips.\n\n\n\nTo answer this we can group by metro area and then summarize for the mean of area. After generating a dataframe with these values we can see Chicago was the highest followed by Las Vegas area, and the lowest was Cheyenne,WY. We can also create a bar graph of the top 10 areas to visualize this clearly. Using the aes (aesthetic) function with fill = metro_area allows for a colorful representation of each chart. This method creates a legend we don’t need so we set show.legend = FALSE. The element text function allows for the X label to be angled and positioned correctly for long label names.\n\n   USAGE &lt;- USAGE %&gt;% rename(\"metro_area\" = \"UZA Name\")#had to rerun this code\n \n   trips_by_area &lt;- USAGE %&gt;% \n        select(year,metro_area,trips) %&gt;% \n        group_by(metro_area) %&gt;% \n        summarise(avg_trips = mean(trips)) %&gt;% \n        arrange(desc(avg_trips)) %&gt;% \n        head(10)\n\n    ggplot(trips_by_area,aes(x = metro_area,y = avg_trips))+\n        geom_bar(stat = 'identity',aes(fill = metro_area),color = \"red\",show.legend = FALSE)+\n        theme_minimal()+\n        theme(axis.text.x = element_text(angle = 45, hjust = 1,vjust = 1))+\n        labs(title = \"Average Trips by City\",y= \"Unlinked Passenger Trips\", x= \"Metro Area\")\n\n\n\n\n\n\n\n\n\n\n\n\nThis task pertains to joining two tables to create a Usage and financial table. We will join on the keys NTD ID and Mode. Since the mode is different in the financial table (recall it was altered for usability) it must also be changed. Grouping by NTD ID and Mode allows for us answer the questions in Task 6 which requires transportation agency and method to be combined, since each agency has its own unique ID this is exactly the same thing.\n\n  USAGE_2022_ANNUAL &lt;- USAGE %&gt;% \n        filter(year == 2022) %&gt;% \n        select('NTD ID',Mode,Agency,metro_area,trips,VRM) %&gt;% \n        group_by(`NTD ID`,Mode) %&gt;% \n        summarise(annual_trips = sum(trips),annual_vrm = sum(VRM)) %&gt;% \n        ungroup()\n\n`summarise()` has grouped output by 'NTD ID'. You can override using the\n`.groups` argument.\n\n      Financials &lt;- Financials |&gt;\n     mutate(Mode=case_when(\n          Mode == \"HR\" ~ \"Heavy Rail\", \n          Mode == \"DR\"~\"Demand Response\",\n          Mode == \"FB\"~\"Ferryboat\",\n          Mode == \"MB\"~\"Bus\",\n          Mode == \"SR\"~\"Streetcar Rail\",\n          Mode == \"TB\"~\"Trolleybus\",\n          Mode == \"VP\"~\"Vanpool\",\n          Mode == \"CB\"~\"Commuter Bus\",\n          Mode == \"RB\"~\"Bus Rapid Transit\",\n          Mode == \"LR\"~\"Light Rail\",\n          Mode == \"YR\"~\"Hybrid Rail\",\n          Mode == \"MG\"~\"Monorail Automated Guideway\",\n          Mode == \"CR\"~\"Commuter Rail\",\n          Mode == \"AR\"~\"Alaska Railroad\",\n          Mode == \"TR\"~\"Aerial Tramway\",\n          Mode == \"IP\"~\"Inclined Plane\",\n          Mode == \"PB\"~\"Publico\",\n          Mode == \"CC\"~\"Cable Car\",\n          TRUE~\"Unknown\"))\n      \n      USAGE_AND_FINANCIALS &lt;- left_join(USAGE_2022_ANNUAL, \n           Financials, \n           join_by(`NTD ID`, Mode)) |&gt;\n           drop_na()\n\n\n\n\n\n\nUsing Group_by and summarize with max( ) we get the answer New York MTA and Heavy Rail.\n\n      USAGE_AND_FINANCIALS %&gt;% \n        group_by(`Agency Name`,`Mode`) %&gt;% \n        summarise(max_trips = max(annual_trips)) %&gt;% \n        arrange(desc(max_trips)) %&gt;% \n        head(1)\n\n# A tibble: 1 × 3\n# Groups:   Agency Name [1]\n  `Agency Name`             Mode        max_trips\n  &lt;chr&gt;                     &lt;chr&gt;           &lt;dbl&gt;\n1 MTA New York City Transit Heavy Rail 1793073801\n\n\n\n\n\nUsing mutate to create another calculated column with the Fare Box Ratio formula we get the answer, Vanpool in the Central Kentucky agency. This makes sense as vanpool is essentially car pooling in small vehicles like vans and small buses for shorter distances. This allows for lower costs then other modes like for example Heavy Rail, which require lots of maintenance and overhead.\n\n      USAGE_AND_FINANCIALS&lt;-USAGE_AND_FINANCIALS %&gt;% \n         group_by(`Agency Name`,`Mode`) %&gt;% \n         mutate(fare_box_recovery = `Total Fares`/Expenses) %&gt;%\n         arrange(desc(fare_box_recovery))\n         print(USAGE_AND_FINANCIALS)\n\n# A tibble: 1,132 × 8\n# Groups:   Agency Name, Mode [1,130]\n   `NTD ID` Mode    annual_trips annual_vrm `Agency Name` `Total Fares` Expenses\n      &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;                 &lt;dbl&gt;    &lt;dbl&gt;\n 1    40191 Vanpool         9640      94027 Transit Auth…         97300    40801\n 2    40034 Vanpool       395004    3091052 County of Mi…       1987879  1191874\n 3    90233 Vanpool        70093     462346 Yuma County …        411216   279585\n 4    20190 Ferryb…      3757873     504037 Port Imperia…      33443241 23417248\n 5    11239 Ferryb…       878728     188694 Hyannis Harb…      25972659 18383764\n 6    11238 Ferryb…        96707      56980 Bay State LLC       6287351  4672351\n 7    20169 Commut…       403646    1259602 Trans-Bridge…      11325199  8495611\n 8    40001 Inclin…       481957      20128 Chattanooga …       3005198  2290714\n 9    66339 Vanpool       118780    1748901 New Mexico D…        757574   588830\n10       12 Vanpool       189684    1582484 Municipality…       1400709  1105911\n# ℹ 1,122 more rows\n# ℹ 1 more variable: fare_box_recovery &lt;dbl&gt;\n\n\n\n\n\nSimilarly we can answer this question.\n\n       USAGE_AND_FINANCIALS %&gt;% \n           group_by(`Agency Name`,`Mode`) %&gt;% \n           mutate(expenses_per_trip = Expenses/annual_trips) %&gt;% \n           select(`Agency Name`,Mode,expenses_per_trip) %&gt;% \n           arrange(expenses_per_trip)\n\n# A tibble: 1,132 × 3\n# Groups:   Agency Name, Mode [1,130]\n   `Agency Name`                                         Mode  expenses_per_trip\n   &lt;chr&gt;                                                 &lt;chr&gt;             &lt;dbl&gt;\n 1 North Carolina State University                       Bus                1.18\n 2 Anaheim Transportation Network                        Bus                1.28\n 3 Valley Metro Rail, Inc.                               Stre…              1.49\n 4 University of Iowa                                    Bus                1.54\n 5 Chatham Area Transit Authority                        Ferr…              1.60\n 6 Texas State University                                Bus                2.05\n 7 South Florida Regional Transportation Authority       Bus                2.27\n 8 University of Georgia                                 Bus                2.31\n 9 Hillsborough Area Regional Transit Authority          Stre…              2.45\n10 University of Michigan Parking and Transportation Se… Bus                2.52\n# ℹ 1,122 more rows\n\n\nIndicates that buses have a low cost per person.\n\n\n\nIn this question, an extra step will be taken for later use to both easily answer more questions and also effectively produce some visualizations based on the given problems. Firstly, using mutate to calculate Fares/ UPT(Trips) grouped by the agency and mode will be enough to answer the question. The second additional step will be to make a new column that contains both the agency and the mode in one column. This will make it easier to get this information, and also will allow use to graph these grouped problems. To do this the use of the stringr library. This library is used for manipulating strings, and in this case it will be used to combine the 2 strings in both agent and mode columns.\n\nlibrary(stringr)\n       fare_per_trip &lt;- USAGE_AND_FINANCIALS %&gt;% \n           group_by(`Agency Name`,`Mode`) %&gt;% \n           mutate(fares_per_trip = `Total Fares`/annual_trips) %&gt;% \n           mutate(Agent_Mode = str_c(`Agency Name`,Mode, sep = \", \")) %&gt;% #joining the col strings with a comma and space\n           arrange(desc(fares_per_trip)) %&gt;% \n           select(`Agency Name`,fares_per_trip,Mode,Agent_Mode) %&gt;%\n           head(10)\n       print(fare_per_trip)\n\n# A tibble: 10 × 4\n# Groups:   Agency Name, Mode [10]\n   `Agency Name`                                 fares_per_trip Mode  Agent_Mode\n   &lt;chr&gt;                                                  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;     \n 1 Altoona Metro Transit                                  660.  Dema… Altoona M…\n 2 Alaska Railroad Corporation                            153.  Alas… Alaska Ra…\n 3 Bay State LLC                                           65.0 Ferr… Bay State…\n 4 Central Pennsylvania Transportation Authority           50.2 Dema… Central P…\n 5 Hampton Jitney, Inc.                                    41.3 Comm… Hampton J…\n 6 County of Placer                                        38.8 Comm… County of…\n 7 Audubon Area Community Services, Inc.                   37.4 Dema… Audubon A…\n 8 Lane Transit District                                   34.0 Dema… Lane Tran…\n 9 Pennsylvania Department of Transportation               32.3 Comm… Pennsylva…\n10 Hyannis Harbor Tours, Inc.                              29.6 Ferr… Hyannis H…\n\n\nWith the new column, removing agent and mode columns.\n\n  fare_per_trip %&gt;% \n     ungroup() %&gt;% \n     select(Agent_Mode,fares_per_trip)\n\n# A tibble: 10 × 2\n   Agent_Mode                                                     fares_per_trip\n   &lt;chr&gt;                                                                   &lt;dbl&gt;\n 1 Altoona Metro Transit, Demand Response                                  660. \n 2 Alaska Railroad Corporation, Alaska Railroad                            153. \n 3 Bay State LLC, Ferryboat                                                 65.0\n 4 Central Pennsylvania Transportation Authority, Demand Response           50.2\n 5 Hampton Jitney, Inc., Commuter Bus                                       41.3\n 6 County of Placer, Commuter Bus                                           38.8\n 7 Audubon Area Community Services, Inc., Demand Response                   37.4\n 8 Lane Transit District, Demand Response                                   34.0\n 9 Pennsylvania Department of Transportation, Commuter Rail                 32.3\n10 Hyannis Harbor Tours, Inc., Ferryboat                                    29.6\n\n\nAs you can see it is very simple to read\nSince the Altoona per trip price is so high, some additional analysis is required.\n\n  USAGE %&gt;%\n    group_by(Mode,Agency) %&gt;% \n    filter(Agency == 'Altoona Metro Transit'& year == 2022) %&gt;% \n    filter(Mode== \"Demand Response\") %&gt;%\n    summarise(total_trips = sum(trips))\n\n`summarise()` has grouped output by 'Mode'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 1 × 3\n# Groups:   Mode [1]\n  Mode            Agency                total_trips\n  &lt;chr&gt;           &lt;chr&gt;                       &lt;dbl&gt;\n1 Demand Response Altoona Metro Transit          26\n\n\n\nUSAGE_AND_FINANCIALS &lt;- USAGE_AND_FINANCIALS %&gt;% \n  mutate(Agent_Mode = str_c(`Agency Name`,Mode, sep = \", \")) #adding to main dataset\n\nUSAGE_AND_FINANCIALS %&gt;%\n    filter(Agent_Mode == 'Altoona Metro Transit, Demand Response') %&gt;% \n    select(Agent_Mode,`Total Fares`)\n\nAdding missing grouping variables: `Agency Name`, `Mode`\n\n\n# A tibble: 1 × 4\n# Groups:   Agency Name, Mode [1]\n  `Agency Name`         Mode            Agent_Mode                 `Total Fares`\n  &lt;chr&gt;                 &lt;chr&gt;           &lt;chr&gt;                              &lt;dbl&gt;\n1 Altoona Metro Transit Demand Response Altoona Metro Transit, De…         17163\n\n\nGiven that there is in fact 26 recorded trips with total fares of 17,163 there might be a chance that some info is missing, and if this is the case then the Alaskan Railroad would be the answer to this problem.\n\n\n\n\n ggplot(fare_per_trip,aes(x = Agent_Mode,y = fares_per_trip))+\n           geom_bar(stat = \"identity\",aes(fill= Agent_Mode),color= 'purple',show.legend = FALSE)+\n           theme_minimal()+\n           theme(axis.text.x = element_text(angle = 45,vjust =1,hjust = 1))+\n           labs(title = \"Fairs Per UPT(Unlinked Passenger Trips)\", x = \"Agency & Mode\",y = \"Fares Per Passenger Trips\")\n\n\n\n\n\n\n\n\n\n\n\nWe can use that new column along with arrange to get the lowest expense per VRM.\n\n         USAGE_AND_FINANCIALS %&gt;% \n           group_by(Agent_Mode) %&gt;% \n           mutate(expenses_per_vrm = Expenses/annual_vrm) %&gt;% \n           arrange(expenses_per_vrm) %&gt;% \n           select(Agent_Mode,expenses_per_vrm) %&gt;% \n           head(5)\n\n# A tibble: 5 × 2\n# Groups:   Agent_Mode [5]\n  Agent_Mode                                                expenses_per_vrm\n  &lt;chr&gt;                                                                &lt;dbl&gt;\n1 New Mexico Department of Transportation, Vanpool                     0.337\n2 VIA Metropolitan Transit, Vanpool                                    0.370\n3 County of Miami-Dade, Vanpool                                        0.386\n4 County of Volusia, Vanpool                                           0.393\n5 Corpus Christi Regional Transportation Authority, Vanpool            0.431\n\n\nUsing arrange(desc( ) ) gives us the ability to get the transit system with the highest expense per VRM.\n\n         USAGE_AND_FINANCIALS %&gt;% \n           group_by(Agent_Mode) %&gt;% \n           filter(annual_vrm != 0) %&gt;% # to avoid dividing by 0\n           mutate(expenses_per_vrm = Expenses/annual_vrm) %&gt;% \n           arrange(desc(expenses_per_vrm)) %&gt;% \n           select(Agent_Mode,expenses_per_vrm) %&gt;% \n           head(5)\n\n# A tibble: 5 × 2\n# Groups:   Agent_Mode [5]\n  Agent_Mode                                                    expenses_per_vrm\n  &lt;chr&gt;                                                                    &lt;dbl&gt;\n1 Altoona Metro Transit, Demand Response                                   1207.\n2 New York City Department of Transportation, Ferryboat                     771.\n3 New Orleans Regional Transit Authority, Ferryboat                         468.\n4 Loop Trolley Transportation Development District, Streetcar …             412.\n5 Washington State Ferries, Ferryboat                                       383.\n\n\nNotice there are several Ferryboats in this descending table. This indicates Ferries are more costly to operate then some of the other Modes like Vanpool, which does make sense.\n\n\n\n\n         fares_vrm&lt;-USAGE_AND_FINANCIALS %&gt;%\n           group_by(Agent_Mode) %&gt;% \n           filter(annual_vrm != 0) %&gt;% # to avoid dividing by 0\n           mutate(fares_per_vrm = `Total Fares`/annual_vrm) %&gt;%\n           arrange(desc(fares_per_vrm)) %&gt;% \n           select(Agent_Mode,fares_per_vrm) %&gt;% \n           head(10)\n         print(fares_vrm)\n\n# A tibble: 10 × 2\n# Groups:   Agent_Mode [10]\n   Agent_Mode                                                      fares_per_vrm\n   &lt;chr&gt;                                                                   &lt;dbl&gt;\n 1 Chicago Water Taxi (Wendella), Ferryboat                                237. \n 2 Altoona Metro Transit, Demand Response                                  229. \n 3 Jacksonville Transportation Authority, Ferryboat                        158. \n 4 Chattanooga Area Regional Transportation Authority, Inclined P…         149. \n 5 Hyannis Harbor Tours, Inc., Ferryboat                                   138. \n 6 SeaStreak, LLC, Ferryboat                                               115. \n 7 Bay State LLC, Ferryboat                                                110. \n 8 Cape May Lewes Ferry, Ferryboat                                          93.0\n 9 Woods Hole, Martha's Vineyard and Nantucket Steamship Authorit…          91.7\n10 Washington State Ferries, Ferryboat                                      78.1\n\n\nThis result shows many Ferryboat modes, which makes sense as ferry’s will be traveling shorter distances while charging the same or more than longer forms of transport.\n\n\n\n\n ggplot(fares_vrm,aes(x = Agent_Mode,y = fares_per_vrm))+\n           geom_bar(stat = \"identity\",aes(fill= Agent_Mode),color= 'lightblue',show.legend = FALSE)+\n           theme_bw()+\n           theme(axis.text.x = element_text(angle = 45,vjust =1,hjust = 1))+\n           labs(title = \"Fairs Per VRM(Vehicle Revenue Miles)\", x = \"Agency & Mode\",y = \"Fares Per VRM\")"
  },
  {
    "objectID": "mp01.html#intro",
    "href": "mp01.html#intro",
    "title": "Mini Project 1",
    "section": "",
    "text": "This analysis looks to provide some insights on the financial information behind some of the biggest transit agencies in the US. The data set being studied includes massive systems like the NYC Metro and also lesser used systems in states like Hawaii and Oklahoma."
  },
  {
    "objectID": "mp01.html#task-one-two-data-cleaning",
    "href": "mp01.html#task-one-two-data-cleaning",
    "title": "Mini Project 1",
    "section": "",
    "text": "After loading the data certain column names and row values need to be changed for syntactic reasons and ease of understanding. Firstly, changing the column UZA Name to metro_area will allow for syntactic ease, and a more intuitive label.\n\nUSAGE &lt;- inner_join(TRIPS, MILES) |&gt;\n    mutate(`NTD ID` = as.integer(`NTD ID`))\n\nJoining with `by = join_by(`NTD ID`, Agency, `UZA Name`, Mode, `3 Mode`,\nmonth)`\n\n    sample_n(USAGE, 1000) |&gt; \n    rename(\"metro_area\" = \"UZA Name\") %&gt;% #renaming UZA\n    mutate(month=as.character(month))\n\n# A tibble: 1,000 × 8\n   `NTD ID` Agency                 metro_area Mode  `3 Mode` month    UPT    VRM\n      &lt;int&gt; &lt;chr&gt;                  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1    20113 Regional Transit Serv… Rochester… MB    Bus      2016… 1.33e6 417338\n 2    50019 City of Middletown     Middletow… DR    Bus      2008… 7.18e2   4172\n 3    30111 Washington County Tra… Pittsburg… MB    Bus      2014… 1.53e3   6581\n 4    20018 Central New York Regi… Syracuse,… DR    Bus      2019… 6.92e3 100968\n 5    60102 Concho Valley Transit… San Angel… MB    Bus      2008… 1.65e4  32176\n 6    50166 Clermont County, Ohio  Cincinnat… MB    Bus      2020… 7.2 e2   8974\n 7    50113 Pace, the Suburban Bu… Chicago, … VP    Bus      2011… 1.47e5 795247\n 8    40093 City of Greensboro     Greensbor… MB    Bus      2011… 3.34e5 164105\n 9    20004 Niagara Frontier Tran… Buffalo, … MB    Bus      2017… 1.73e6 665018\n10        7 Lane Transit District  Eugene, OR MB    Bus      2020… 1.15e3 124987\n# ℹ 990 more rows\n\n\nThe second section will be “re-coding” the Mode date in the dataframe. Since the data originally had codes like “HR” for Heavy Rail, or “FB” for Ferry Boat it will be hard for someone ignorant of these codes to understand the meaning behind them. So we will find all the distinct values, search their meanings, and then rename those values. The results will be displayed a Data Table using the DT library\n\n  distinct_modes&lt;- USAGE %&gt;% distinct(Mode)\n \n   USAGE &lt;- USAGE |&gt;\n     mutate(Mode=case_when(\n          Mode == \"HR\" ~ \"Heavy Rail\", \n          Mode == \"DR\"~\"Demand Response\",\n          Mode == \"FB\"~\"Ferryboat\",\n          Mode == \"MB\"~\"Bus\",\n          Mode == \"SR\"~\"Streetcar Rail\",\n          Mode == \"TB\"~\"Trolleybus\",\n          Mode == \"VP\"~\"Vanpool\",\n          Mode == \"CB\"~\"Commuter Bus\",\n          Mode == \"RB\"~\"Bus Rapid Transit\",\n          Mode == \"LR\"~\"Light Rail\",\n          Mode == \"YR\"~\"Hybrid Rail\",\n          Mode == \"MG\"~\"Monorail Automated Guideway\",\n          Mode == \"CR\"~\"Commuter Rail\",\n          Mode == \"AR\"~\"Alaska Railroad\",\n          Mode == \"TR\"~\"Aerial Tramway\",\n          Mode == \"IP\"~\"Inclined Plane\",\n          Mode == \"PB\"~\"Publico\",\n          Mode == \"CC\"~\"Cable Car\",\n          TRUE~\"Unknown\"))\n    Use_table &lt;- DT::datatable(head(USAGE, 5000))"
  },
  {
    "objectID": "mp01.html#task-3-answering-questions-using-dyplr",
    "href": "mp01.html#task-3-answering-questions-using-dyplr",
    "title": "Mini Project 1",
    "section": "",
    "text": "Using the arrange function we can sort the data based on a ascending or descending order of a specified value. Using arrange combined with desc function we get the all the VRM values starting from highest to lowest. The corresponding agency will be the answer.\n\nMax_VRM &lt;- USAGE %&gt;% \n    select(VRM,Agency) %&gt;%\n    arrange(desc(VRM)) %&gt;% \n    head(1)\n    print(Max_VRM)\n\n# A tibble: 1 × 2\n       VRM Agency                   \n     &lt;dbl&gt; &lt;chr&gt;                    \n1 30882144 MTA New York City Transit\n\n\n\n\n\nUsing the same idea as the previous question, this time combining it with the group_by function will allow us to find the answer. The group_by function creates “groups” of a given variable to then perform some action to those groups. In this case we will group by the mode and then sum up the VRM for each mode. This method will provide the answer “Bus”\n\nvrm_by_mode &lt;- USAGE %&gt;% \n    select(VRM,Mode) %&gt;%\n    group_by(Mode) %&gt;% \n    summarise(Total = sum(VRM)) %&gt;% \n    arrange(desc(Total))\n    print(vrm_by_mode)\n\n# A tibble: 18 × 2\n   Mode                              Total\n   &lt;chr&gt;                             &lt;dbl&gt;\n 1 Bus                         49444494088\n 2 Demand Response             17955073508\n 3 Heavy Rail                  14620362107\n 4 Commuter Rail                6970644241\n 5 Vanpool                      3015783362\n 6 Light Rail                   2090094714\n 7 Commuter Bus                 1380948975\n 8 Publico                      1021270808\n 9 Trolleybus                    236840288\n10 Bus Rapid Transit             118425283\n11 Ferryboat                      65589783\n12 Streetcar Rail                 63389725\n13 Monorail Automated Guideway    37879729\n14 Hybrid Rail                    37787608\n15 Alaska Railroad                13833261\n16 Cable Car                       7386019\n17 Inclined Plane                   705904\n18 Aerial Tramway                   292860\n\n\n\n\n\nTo answer this the use of the filter function is required. The filter function will remove all the data that doesn’t agree with the filter statement, allowing for more specific analysis. Filtering for a May 2024 date and a NYC MTA Agency Subway will give the answer, but first some data manipulating is required. Creating a year and month column with the lubridate library, allows for quick and easy date time analysis and will come in handy, making future analysis streamlined. After doing so the previous techniques are used.\n\n  typeof(USAGE$month)#checking the type of column month is\n\n[1] \"double\"\n\nlibrary(lubridate)\n  USAGE$month &lt;- ymd(USAGE$month) #changing to date format\n  USAGE &lt;- USAGE %&gt;% \n     rename(\"trips\"=UPT) %&gt;% #renaming the UPT(Unlinked passenger trips)- to trips\n     rename(\"date\"=month) %&gt;%  \n     mutate(\"year\"= year(date)) %&gt;%\n     mutate('month'= month(date))\n  nyc_trips &lt;- USAGE %&gt;% \n    filter(Agency == \"MTA New York City Transit\" & Mode ==\"Heavy Rail\")%&gt;% \n    filter(year==2024 & month == 5) %&gt;% \n    summarise(may_total=sum(trips))\n    print(nyc_trips)\n\n# A tibble: 1 × 1\n  may_total\n      &lt;dbl&gt;\n1 180458819\n\n\n\n\n\nUsing all the techniques from the previous questions, along with the pull method to give a singular value will provide an answer for this question. After pulling the data for both cases we can simply find the difference.\n\n  nyc_monthly &lt;- USAGE %&gt;% #this table provides info that might be useful later on\n    filter(Agency == 'MTA New York City Transit' & Mode == 'Heavy Rail') %&gt;% \n    group_by(year, month) %&gt;%                       \n    mutate(total_vrm = sum(VRM)) %&gt;% \n    mutate(total_trips = sum(trips)) %&gt;%\n    select(year,month,total_trips,total_vrm)\n   vrm_2019 &lt;- nyc_monthly %&gt;%\n    filter(year == 2019 & month == 4) %&gt;% \n    pull(total_vrm)\n  \n  vrm_2020 &lt;- nyc_monthly %&gt;%\n    filter(year == 2020 & month == 4) %&gt;% \n    pull(total_vrm)\n  \n  print(\"VRM Difference\")\n\n[1] \"VRM Difference\"\n\n  vrm_2019-vrm_2020 #difference in Vehicle Revenue Miles\n\n[1] 12200677\n\n  trips_2019 &lt;- nyc_monthly %&gt;%\n    filter(year == 2019 & month == 4) %&gt;% \n    pull(total_trips)\n  \n  trips_2020 &lt;- nyc_monthly %&gt;%\n    filter(year == 2020 & month == 4) %&gt;% \n    pull(total_trips)\n  print(\"Trips Difference\")\n\n[1] \"Trips Difference\"\n\n  trips_2019-trips_2020 #decrease in trips\n\n[1] 211969660\n\n\n\n\n\n\n\nUsing a combintion of techniques like filtering, summarize, as well as grouping by the month column will provide the answer.\n\n     USAGE %&gt;% \n     filter(year == 2023) %&gt;% \n     select(year,month,VRM) %&gt;% \n     group_by(month) %&gt;% \n     summarise(total_vrm = sum(VRM)) %&gt;% \n     arrange(desc(total_vrm))\n\n# A tibble: 12 × 2\n   month total_vrm\n   &lt;dbl&gt;     &lt;dbl&gt;\n 1     8 422002435\n 2    10 420684229\n 3     3 413311032\n 4     5 407605645\n 5    11 402542477\n 6     6 400875583\n 7    12 399428041\n 8     7 398685473\n 9     9 398172153\n10     1 389141732\n11     4 386876164\n12     2 361882307\n\n\n\n\n\nSimilarly with this question grouping by year and computing the desired value, using mutate this time, gives us the answer. We can also plot this to see some yearly trends using ggplot.\n\n  yearly_trips &lt;- USAGE %&gt;% \n     group_by(year) %&gt;% \n     mutate(total_trips = sum(trips)) %&gt;%\n     mutate(avg_trip_day = total_trips/365) %&gt;% \n     select(year,total_trips,avg_trip_day) %&gt;% \n     arrange(desc(total_trips)) %&gt;% \n     distinct(year,total_trips,avg_trip_day)\n     #plotting\n     ggplot(yearly_trips,aes(x= year,y=avg_trip_day))+\n       geom_line(color = 'blue')+\n       labs(title = \"Trends in Avg Trips Per Day\", y = \"Unlinked Trips\",x = \"Years\")+\n       theme_minimal()\n\n\n\n\n\n\n\n\nPredictably, there is a huge drop in 2020 in average trips.\n\n\n\nTo answer this we can group by metro area and then summarize for the mean of area. After generating a dataframe with these values we can see Chicago was the highest followed by Las Vegas area, and the lowest was Cheyenne,WY. We can also create a bar graph of the top 10 areas to visualize this clearly. Using the aes (aesthetic) function with fill = metro_area allows for a colorful representation of each chart. This method creates a legend we don’t need so we set show.legend = FALSE. The element text function allows for the X label to be angled and positioned correctly for long label names.\n\n   USAGE &lt;- USAGE %&gt;% rename(\"metro_area\" = \"UZA Name\")#had to rerun this code\n \n   trips_by_area &lt;- USAGE %&gt;% \n        select(year,metro_area,trips) %&gt;% \n        group_by(metro_area) %&gt;% \n        summarise(avg_trips = mean(trips)) %&gt;% \n        arrange(desc(avg_trips)) %&gt;% \n        head(10)\n\n    ggplot(trips_by_area,aes(x = metro_area,y = avg_trips))+\n        geom_bar(stat = 'identity',aes(fill = metro_area),color = \"red\",show.legend = FALSE)+\n        theme_minimal()+\n        theme(axis.text.x = element_text(angle = 45, hjust = 1,vjust = 1))+\n        labs(title = \"Average Trips by City\",y= \"Unlinked Passenger Trips\", x= \"Metro Area\")\n\n\n\n\n\n\n\n\n\n\n\n\nThis task pertains to joining two tables to create a Usage and financial table. We will join on the keys NTD ID and Mode. Since the mode is different in the financial table (recall it was altered for usability) it must also be changed. Grouping by NTD ID and Mode allows for us answer the questions in Task 6 which requires transportation agency and method to be combined, since each agency has its own unique ID this is exactly the same thing.\n\n  USAGE_2022_ANNUAL &lt;- USAGE %&gt;% \n        filter(year == 2022) %&gt;% \n        select('NTD ID',Mode,Agency,metro_area,trips,VRM) %&gt;% \n        group_by(`NTD ID`,Mode) %&gt;% \n        summarise(annual_trips = sum(trips),annual_vrm = sum(VRM)) %&gt;% \n        ungroup()\n\n`summarise()` has grouped output by 'NTD ID'. You can override using the\n`.groups` argument.\n\n      Financials &lt;- Financials |&gt;\n     mutate(Mode=case_when(\n          Mode == \"HR\" ~ \"Heavy Rail\", \n          Mode == \"DR\"~\"Demand Response\",\n          Mode == \"FB\"~\"Ferryboat\",\n          Mode == \"MB\"~\"Bus\",\n          Mode == \"SR\"~\"Streetcar Rail\",\n          Mode == \"TB\"~\"Trolleybus\",\n          Mode == \"VP\"~\"Vanpool\",\n          Mode == \"CB\"~\"Commuter Bus\",\n          Mode == \"RB\"~\"Bus Rapid Transit\",\n          Mode == \"LR\"~\"Light Rail\",\n          Mode == \"YR\"~\"Hybrid Rail\",\n          Mode == \"MG\"~\"Monorail Automated Guideway\",\n          Mode == \"CR\"~\"Commuter Rail\",\n          Mode == \"AR\"~\"Alaska Railroad\",\n          Mode == \"TR\"~\"Aerial Tramway\",\n          Mode == \"IP\"~\"Inclined Plane\",\n          Mode == \"PB\"~\"Publico\",\n          Mode == \"CC\"~\"Cable Car\",\n          TRUE~\"Unknown\"))\n      \n      USAGE_AND_FINANCIALS &lt;- left_join(USAGE_2022_ANNUAL, \n           Financials, \n           join_by(`NTD ID`, Mode)) |&gt;\n           drop_na()\n\n\n\n\n\n\nUsing Group_by and summarize with max( ) we get the answer New York MTA and Heavy Rail.\n\n      USAGE_AND_FINANCIALS %&gt;% \n        group_by(`Agency Name`,`Mode`) %&gt;% \n        summarise(max_trips = max(annual_trips)) %&gt;% \n        arrange(desc(max_trips)) %&gt;% \n        head(1)\n\n# A tibble: 1 × 3\n# Groups:   Agency Name [1]\n  `Agency Name`             Mode        max_trips\n  &lt;chr&gt;                     &lt;chr&gt;           &lt;dbl&gt;\n1 MTA New York City Transit Heavy Rail 1793073801\n\n\n\n\n\nUsing mutate to create another calculated column with the Fare Box Ratio formula we get the answer, Vanpool in the Central Kentucky agency. This makes sense as vanpool is essentially car pooling in small vehicles like vans and small buses for shorter distances. This allows for lower costs then other modes like for example Heavy Rail, which require lots of maintenance and overhead.\n\n      USAGE_AND_FINANCIALS&lt;-USAGE_AND_FINANCIALS %&gt;% \n         group_by(`Agency Name`,`Mode`) %&gt;% \n         mutate(fare_box_recovery = `Total Fares`/Expenses) %&gt;%\n         arrange(desc(fare_box_recovery))\n         print(USAGE_AND_FINANCIALS)\n\n# A tibble: 1,132 × 8\n# Groups:   Agency Name, Mode [1,130]\n   `NTD ID` Mode    annual_trips annual_vrm `Agency Name` `Total Fares` Expenses\n      &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;                 &lt;dbl&gt;    &lt;dbl&gt;\n 1    40191 Vanpool         9640      94027 Transit Auth…         97300    40801\n 2    40034 Vanpool       395004    3091052 County of Mi…       1987879  1191874\n 3    90233 Vanpool        70093     462346 Yuma County …        411216   279585\n 4    20190 Ferryb…      3757873     504037 Port Imperia…      33443241 23417248\n 5    11239 Ferryb…       878728     188694 Hyannis Harb…      25972659 18383764\n 6    11238 Ferryb…        96707      56980 Bay State LLC       6287351  4672351\n 7    20169 Commut…       403646    1259602 Trans-Bridge…      11325199  8495611\n 8    40001 Inclin…       481957      20128 Chattanooga …       3005198  2290714\n 9    66339 Vanpool       118780    1748901 New Mexico D…        757574   588830\n10       12 Vanpool       189684    1582484 Municipality…       1400709  1105911\n# ℹ 1,122 more rows\n# ℹ 1 more variable: fare_box_recovery &lt;dbl&gt;\n\n\n\n\n\nSimilarly we can answer this question.\n\n       USAGE_AND_FINANCIALS %&gt;% \n           group_by(`Agency Name`,`Mode`) %&gt;% \n           mutate(expenses_per_trip = Expenses/annual_trips) %&gt;% \n           select(`Agency Name`,Mode,expenses_per_trip) %&gt;% \n           arrange(expenses_per_trip)\n\n# A tibble: 1,132 × 3\n# Groups:   Agency Name, Mode [1,130]\n   `Agency Name`                                         Mode  expenses_per_trip\n   &lt;chr&gt;                                                 &lt;chr&gt;             &lt;dbl&gt;\n 1 North Carolina State University                       Bus                1.18\n 2 Anaheim Transportation Network                        Bus                1.28\n 3 Valley Metro Rail, Inc.                               Stre…              1.49\n 4 University of Iowa                                    Bus                1.54\n 5 Chatham Area Transit Authority                        Ferr…              1.60\n 6 Texas State University                                Bus                2.05\n 7 South Florida Regional Transportation Authority       Bus                2.27\n 8 University of Georgia                                 Bus                2.31\n 9 Hillsborough Area Regional Transit Authority          Stre…              2.45\n10 University of Michigan Parking and Transportation Se… Bus                2.52\n# ℹ 1,122 more rows\n\n\nIndicates that buses have a low cost per person.\n\n\n\nIn this question, an extra step will be taken for later use to both easily answer more questions and also effectively produce some visualizations based on the given problems. Firstly, using mutate to calculate Fares/ UPT(Trips) grouped by the agency and mode will be enough to answer the question. The second additional step will be to make a new column that contains both the agency and the mode in one column. This will make it easier to get this information, and also will allow use to graph these grouped problems. To do this the use of the stringr library. This library is used for manipulating strings, and in this case it will be used to combine the 2 strings in both agent and mode columns.\n\nlibrary(stringr)\n       fare_per_trip &lt;- USAGE_AND_FINANCIALS %&gt;% \n           group_by(`Agency Name`,`Mode`) %&gt;% \n           mutate(fares_per_trip = `Total Fares`/annual_trips) %&gt;% \n           mutate(Agent_Mode = str_c(`Agency Name`,Mode, sep = \", \")) %&gt;% #joining the col strings with a comma and space\n           arrange(desc(fares_per_trip)) %&gt;% \n           select(`Agency Name`,fares_per_trip,Mode,Agent_Mode) %&gt;%\n           head(10)\n       print(fare_per_trip)\n\n# A tibble: 10 × 4\n# Groups:   Agency Name, Mode [10]\n   `Agency Name`                                 fares_per_trip Mode  Agent_Mode\n   &lt;chr&gt;                                                  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;     \n 1 Altoona Metro Transit                                  660.  Dema… Altoona M…\n 2 Alaska Railroad Corporation                            153.  Alas… Alaska Ra…\n 3 Bay State LLC                                           65.0 Ferr… Bay State…\n 4 Central Pennsylvania Transportation Authority           50.2 Dema… Central P…\n 5 Hampton Jitney, Inc.                                    41.3 Comm… Hampton J…\n 6 County of Placer                                        38.8 Comm… County of…\n 7 Audubon Area Community Services, Inc.                   37.4 Dema… Audubon A…\n 8 Lane Transit District                                   34.0 Dema… Lane Tran…\n 9 Pennsylvania Department of Transportation               32.3 Comm… Pennsylva…\n10 Hyannis Harbor Tours, Inc.                              29.6 Ferr… Hyannis H…\n\n\nWith the new column, removing agent and mode columns.\n\n  fare_per_trip %&gt;% \n     ungroup() %&gt;% \n     select(Agent_Mode,fares_per_trip)\n\n# A tibble: 10 × 2\n   Agent_Mode                                                     fares_per_trip\n   &lt;chr&gt;                                                                   &lt;dbl&gt;\n 1 Altoona Metro Transit, Demand Response                                  660. \n 2 Alaska Railroad Corporation, Alaska Railroad                            153. \n 3 Bay State LLC, Ferryboat                                                 65.0\n 4 Central Pennsylvania Transportation Authority, Demand Response           50.2\n 5 Hampton Jitney, Inc., Commuter Bus                                       41.3\n 6 County of Placer, Commuter Bus                                           38.8\n 7 Audubon Area Community Services, Inc., Demand Response                   37.4\n 8 Lane Transit District, Demand Response                                   34.0\n 9 Pennsylvania Department of Transportation, Commuter Rail                 32.3\n10 Hyannis Harbor Tours, Inc., Ferryboat                                    29.6\n\n\nAs you can see it is very simple to read\nSince the Altoona per trip price is so high, some additional analysis is required.\n\n  USAGE %&gt;%\n    group_by(Mode,Agency) %&gt;% \n    filter(Agency == 'Altoona Metro Transit'& year == 2022) %&gt;% \n    filter(Mode== \"Demand Response\") %&gt;%\n    summarise(total_trips = sum(trips))\n\n`summarise()` has grouped output by 'Mode'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 1 × 3\n# Groups:   Mode [1]\n  Mode            Agency                total_trips\n  &lt;chr&gt;           &lt;chr&gt;                       &lt;dbl&gt;\n1 Demand Response Altoona Metro Transit          26\n\n\n\nUSAGE_AND_FINANCIALS &lt;- USAGE_AND_FINANCIALS %&gt;% \n  mutate(Agent_Mode = str_c(`Agency Name`,Mode, sep = \", \")) #adding to main dataset\n\nUSAGE_AND_FINANCIALS %&gt;%\n    filter(Agent_Mode == 'Altoona Metro Transit, Demand Response') %&gt;% \n    select(Agent_Mode,`Total Fares`)\n\nAdding missing grouping variables: `Agency Name`, `Mode`\n\n\n# A tibble: 1 × 4\n# Groups:   Agency Name, Mode [1]\n  `Agency Name`         Mode            Agent_Mode                 `Total Fares`\n  &lt;chr&gt;                 &lt;chr&gt;           &lt;chr&gt;                              &lt;dbl&gt;\n1 Altoona Metro Transit Demand Response Altoona Metro Transit, De…         17163\n\n\nGiven that there is in fact 26 recorded trips with total fares of 17,163 there might be a chance that some info is missing, and if this is the case then the Alaskan Railroad would be the answer to this problem.\n\n\n\n\n ggplot(fare_per_trip,aes(x = Agent_Mode,y = fares_per_trip))+\n           geom_bar(stat = \"identity\",aes(fill= Agent_Mode),color= 'purple',show.legend = FALSE)+\n           theme_minimal()+\n           theme(axis.text.x = element_text(angle = 45,vjust =1,hjust = 1))+\n           labs(title = \"Fairs Per UPT(Unlinked Passenger Trips)\", x = \"Agency & Mode\",y = \"Fares Per Passenger Trips\")\n\n\n\n\n\n\n\n\n\n\n\nWe can use that new column along with arrange to get the lowest expense per VRM.\n\n         USAGE_AND_FINANCIALS %&gt;% \n           group_by(Agent_Mode) %&gt;% \n           mutate(expenses_per_vrm = Expenses/annual_vrm) %&gt;% \n           arrange(expenses_per_vrm) %&gt;% \n           select(Agent_Mode,expenses_per_vrm) %&gt;% \n           head(5)\n\n# A tibble: 5 × 2\n# Groups:   Agent_Mode [5]\n  Agent_Mode                                                expenses_per_vrm\n  &lt;chr&gt;                                                                &lt;dbl&gt;\n1 New Mexico Department of Transportation, Vanpool                     0.337\n2 VIA Metropolitan Transit, Vanpool                                    0.370\n3 County of Miami-Dade, Vanpool                                        0.386\n4 County of Volusia, Vanpool                                           0.393\n5 Corpus Christi Regional Transportation Authority, Vanpool            0.431\n\n\nUsing arrange(desc( ) ) gives us the ability to get the transit system with the highest expense per VRM.\n\n         USAGE_AND_FINANCIALS %&gt;% \n           group_by(Agent_Mode) %&gt;% \n           filter(annual_vrm != 0) %&gt;% # to avoid dividing by 0\n           mutate(expenses_per_vrm = Expenses/annual_vrm) %&gt;% \n           arrange(desc(expenses_per_vrm)) %&gt;% \n           select(Agent_Mode,expenses_per_vrm) %&gt;% \n           head(5)\n\n# A tibble: 5 × 2\n# Groups:   Agent_Mode [5]\n  Agent_Mode                                                    expenses_per_vrm\n  &lt;chr&gt;                                                                    &lt;dbl&gt;\n1 Altoona Metro Transit, Demand Response                                   1207.\n2 New York City Department of Transportation, Ferryboat                     771.\n3 New Orleans Regional Transit Authority, Ferryboat                         468.\n4 Loop Trolley Transportation Development District, Streetcar …             412.\n5 Washington State Ferries, Ferryboat                                       383.\n\n\nNotice there are several Ferryboats in this descending table. This indicates Ferries are more costly to operate then some of the other Modes like Vanpool, which does make sense.\n\n\n\n\n         fares_vrm&lt;-USAGE_AND_FINANCIALS %&gt;%\n           group_by(Agent_Mode) %&gt;% \n           filter(annual_vrm != 0) %&gt;% # to avoid dividing by 0\n           mutate(fares_per_vrm = `Total Fares`/annual_vrm) %&gt;%\n           arrange(desc(fares_per_vrm)) %&gt;% \n           select(Agent_Mode,fares_per_vrm) %&gt;% \n           head(10)\n         print(fares_vrm)\n\n# A tibble: 10 × 2\n# Groups:   Agent_Mode [10]\n   Agent_Mode                                                      fares_per_vrm\n   &lt;chr&gt;                                                                   &lt;dbl&gt;\n 1 Chicago Water Taxi (Wendella), Ferryboat                                237. \n 2 Altoona Metro Transit, Demand Response                                  229. \n 3 Jacksonville Transportation Authority, Ferryboat                        158. \n 4 Chattanooga Area Regional Transportation Authority, Inclined P…         149. \n 5 Hyannis Harbor Tours, Inc., Ferryboat                                   138. \n 6 SeaStreak, LLC, Ferryboat                                               115. \n 7 Bay State LLC, Ferryboat                                                110. \n 8 Cape May Lewes Ferry, Ferryboat                                          93.0\n 9 Woods Hole, Martha's Vineyard and Nantucket Steamship Authorit…          91.7\n10 Washington State Ferries, Ferryboat                                      78.1\n\n\nThis result shows many Ferryboat modes, which makes sense as ferry’s will be traveling shorter distances while charging the same or more than longer forms of transport.\n\n\n\n\n ggplot(fares_vrm,aes(x = Agent_Mode,y = fares_per_vrm))+\n           geom_bar(stat = \"identity\",aes(fill= Agent_Mode),color= 'lightblue',show.legend = FALSE)+\n           theme_bw()+\n           theme(axis.text.x = element_text(angle = 45,vjust =1,hjust = 1))+\n           labs(title = \"Fairs Per VRM(Vehicle Revenue Miles)\", x = \"Agency & Mode\",y = \"Fares Per VRM\")"
  },
  {
    "objectID": "MP02.html",
    "href": "MP02.html",
    "title": "Mini Project#2 - Hollywood Analysis",
    "section": "",
    "text": "This project examines trends in IMDb movie data to understand factors influencing film success. It focuses on genre popularity and critical ratings over time, uncovering what makes a successful film project. We can then use this analysis to pitch a new project.\n\n\nSince the data is very large we will need to reduce the size of the data by filtering out the information that is not useful for analysis. We can do this by removing people with less than 2 “known for” title credits and also removing rare movies with less than 100 ratings.\n\n\nShow the code\nlibrary(ggplot2)\nTITLE_RATINGS |&gt;\n    ggplot(aes(x=numVotes)) + \n    geom_histogram(bins=30,fill='blue') +\n    xlab(\"Number of IMDB Ratings\") + \n    ylab(\"Number of Titles\") + \n    ggtitle(\"Majority of IMDB Titles Have Less than 100 Ratings\") + \n    theme_bw() + \n    scale_x_log10(label=scales::comma) + \n    scale_y_continuous(label=scales::comma)\n\n\n\n\n\n\n\n\n\nThe graph above is a great representation of the distribution of the our movie data with number of ratings as a descriptor. Showcases how a significant chunk of our date has a number of ratings that is less than 100.\n\n\n\n\n\nShow the code\nlibrary(stringr)\nlibrary(dplyr)\nNAME_BASICS &lt;- NAME_BASICS |&gt; \n  filter(str_count(knownForTitles, \",\") &gt; 1) #filtering the known for titles\n#removing those titles that have less than 100 ratings\n\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n    filter(numVotes &gt;= 100)\n# now using this to reduced date to filter all the other tables with semi_join \nTITLE_BASICS &lt;- TITLE_BASICS |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(tconst == tconst))\n\nTITLE_CREW &lt;- TITLE_CREW |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(tconst == tconst))\n\nTITLE_EPISODES_1 &lt;- TITLE_EPISODES |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(tconst == tconst))\nTITLE_EPISODES_2 &lt;- TITLE_EPISODES |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(parentTconst == tconst))\n\nTITLE_EPISODES &lt;- bind_rows(TITLE_EPISODES_1,\n                            TITLE_EPISODES_2) |&gt;\n    distinct()\n\nTITLE_PRINCIPALS &lt;- TITLE_PRINCIPALS |&gt;\n    semi_join(TITLE_RATINGS, join_by(tconst == tconst))\n\nrm(TITLE_EPISODES_1)\nrm(TITLE_EPISODES_2)\n\n\nThe code above uses a semi-join to filter the other tables, ensuring that they only retain rows with keys that match those in the initial table without actually joining any tables together.\n\n\n\nMost of the time, data will contain many discrepancies. In the case of this data the source used the character \\\\N to representing a missing value within numeric columns. This raises two problems, firstly R does not recognize \\\\N as null, and the columns that should be numeric are in the string format. We can fix both by using as.numeric , which will convert the columns into numeric and also turn unrecognized strings into NAs.\n\n\nShow the code\n### Cleaning the data ####\nglimpse(TITLE_BASICS)\n\n\nRows: 374,145\nColumns: 9\n$ tconst         &lt;chr&gt; \"tt0000001\", \"tt0000002\", \"tt0000003\", \"tt0000004\", \"tt…\n$ titleType      &lt;chr&gt; \"short\", \"short\", \"short\", \"short\", \"short\", \"short\", \"…\n$ primaryTitle   &lt;chr&gt; \"Carmencita\", \"Le clown et ses chiens\", \"Poor Pierrot\",…\n$ originalTitle  &lt;chr&gt; \"Carmencita\", \"Le clown et ses chiens\", \"Pauvre Pierrot…\n$ isAdult        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ startYear      &lt;chr&gt; \"1894\", \"1892\", \"1892\", \"1892\", \"1893\", \"1894\", \"1894\",…\n$ endYear        &lt;chr&gt; \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\",…\n$ runtimeMinutes &lt;chr&gt; \"1\", \"5\", \"5\", \"12\", \"1\", \"1\", \"1\", \"1\", \"45\", \"1\", \"1\"…\n$ genres         &lt;chr&gt; \"Documentary,Short\", \"Animation,Short\", \"Animation,Come…\n\n\nShow the code\nprint(\"________________\")\n\n\n[1] \"________________\"\n\n\nShow the code\nglimpse(TITLE_EPISODES)\n\n\nRows: 3,022,865\nColumns: 4\n$ tconst        &lt;chr&gt; \"tt0045960\", \"tt0046855\", \"tt0048378\", \"tt0048562\", \"tt0…\n$ parentTconst  &lt;chr&gt; \"tt0044284\", \"tt0046643\", \"tt0047702\", \"tt0047768\", \"tt0…\n$ seasonNumber  &lt;chr&gt; \"2\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"3\", \"3\", \"…\n$ episodeNumber &lt;chr&gt; \"3\", \"4\", \"6\", \"10\", \"4\", \"20\", \"5\", \"2\", \"20\", \"6\", \"2\"…\n\n\nShow the code\nNAME_BASICS &lt;- NAME_BASICS |&gt;\n    mutate(birthYear = as.numeric(birthYear),\n           deathYear = as.numeric(deathYear)) # using the as numeric to force non-numeric into actual N/A instead of the \\\\N.R provides by the data\n\n\nWarning: There were 2 warnings in `mutate()`.\nThe first warning was:\nℹ In argument: `birthYear = as.numeric(birthYear)`.\nCaused by warning:\n! NAs introduced by coercion\nℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n\n\nShow the code\nTITLE_BASICS &lt;- TITLE_BASICS |&gt;\n    mutate(startYear = as.numeric(startYear),\n           endYear = as.numeric(endYear),\n           isAdult = as.logical(isAdult))\n\n\nWarning: There were 2 warnings in `mutate()`.\nThe first warning was:\nℹ In argument: `startYear = as.numeric(startYear)`.\nCaused by warning:\n! NAs introduced by coercion\nℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n\n\nShow the code\nTITLE_EPISODES &lt;- TITLE_EPISODES |&gt;\n    mutate(seasonNumber = as.numeric(seasonNumber),\n           episodeNumber = as.numeric(episodeNumber))\n\n\nWarning: There were 2 warnings in `mutate()`.\nThe first warning was:\nℹ In argument: `seasonNumber = as.numeric(seasonNumber)`.\nCaused by warning:\n! NAs introduced by coercion\nℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n\n\nOur data also contains rows that have multiple values per cell. Separating these into their own rows will allow us to do a more detailed analysis later on. The code below does exactly that.\n\n\nShow the code\nNAME_BASICS |&gt; separate_longer_delim(knownForTitles, \",\") |&gt; slice_head(n=10)\n\n\n      nconst     primaryName birthYear deathYear\n1  nm0000001    Fred Astaire      1899      1987\n2  nm0000001    Fred Astaire      1899      1987\n3  nm0000001    Fred Astaire      1899      1987\n4  nm0000001    Fred Astaire      1899      1987\n5  nm0000002   Lauren Bacall      1924      2014\n6  nm0000002   Lauren Bacall      1924      2014\n7  nm0000002   Lauren Bacall      1924      2014\n8  nm0000002   Lauren Bacall      1924      2014\n9  nm0000003 Brigitte Bardot      1934        NA\n10 nm0000003 Brigitte Bardot      1934        NA\n                    primaryProfession knownForTitles\n1        actor,miscellaneous,producer      tt0050419\n2        actor,miscellaneous,producer      tt0072308\n3        actor,miscellaneous,producer      tt0053137\n4        actor,miscellaneous,producer      tt0027125\n5  actress,soundtrack,archive_footage      tt0037382\n6  actress,soundtrack,archive_footage      tt0075213\n7  actress,soundtrack,archive_footage      tt0117057\n8  actress,soundtrack,archive_footage      tt0038355\n9   actress,music_department,producer      tt0057345\n10  actress,music_department,producer      tt0049189\n\n\n\n\n\n\n\nTo answer this question we can first find out which table provides the answer efficiently. Looking at the tables, TITLE_BASICS seems to contain the most relevant information. By first using the Unique function on the title type column, we can see how best to filter our data to count each category.\n\n\nShow the code\n  unique(TITLE_BASICS$titleType)\n\n\n [1] \"short\"        \"movie\"        \"tvSeries\"     \"tvShort\"      \"tvMovie\"     \n [6] \"tvEpisode\"    \"tvMiniSeries\" \"video\"        \"tvSpecial\"    \"videoGame\"   \n\n\nThis shows us all the categories in the column and how to properly query them without scrolling through hundreds of rows of data. This shows some interesting information like the video game category which you wouldn’t expect to see on a film database\n\n\nShow the code\ncat(\"Number of Movies in Data:\",  TITLE_BASICS %&gt;% filter(titleType == \"movie\") %&gt;% summarise(count = n()) %&gt;% pull(count),\"\\n\") \n\n\nNumber of Movies in Data: 132220 \n\n\nShow the code\ncat(\"Number of TV Series:\", TITLE_BASICS %&gt;% filter(titleType == \"tvSeries\") %&gt;% summarise(count = n()) %&gt;% pull(count),\"\\n\")\n\n\nNumber of TV Series: 29986 \n\n\nShow the code\ncat(\"Number of TV episodes:\", TITLE_BASICS %&gt;% filter(titleType == \"tvEpisode\") %&gt;% summarise(count = n()) %&gt;% pull(count))\n\n\nNumber of TV episodes: 156725\n\n\n\n\n\nIn order to get an accurate answer, and basing it mostly on the data at hand we must use the filter function for living people and getting the minimum birth year that makes sense. This assumes that the death date is in fact accurate and is a death date. Something to note is that at least one group of people is listed in this table, under the name Cherry Bullet with a death date of 2024. This data point is misleading as this is not a single person but a KPOP group, and the death date is the date the band separated.\n\n\nShow the code\nNAME_BASICS %&gt;% filter(is.na(deathYear),!is.na(birthYear), 2024-birthYear &lt;= 100) %&gt;% arrange(birthYear) %&gt;% head(10)\n\n\n      nconst              primaryName birthYear deathYear\n1  nm0001693          Eva Marie Saint      1924        NA\n2  nm0011140                Lee Adams      1924        NA\n3  nm0021786         Humberto Almazán      1924        NA\n4  nm0073561        Yuriy Berenshteyn      1924        NA\n5  nm0080310 Harsukh Jagneshwar Bhatt      1924        NA\n6  nm0084762          Bo Bjelfvenstam      1924        NA\n7  nm0097155            Carola Bornée      1924        NA\n8  nm0106849            Pietro Bregni      1924        NA\n9  nm0121557             Michael Burk      1924        NA\n10 nm0130807          Hillevi Calvert      1924        NA\n                      primaryProfession\n1           actress,producer,soundtrack\n2  music_department,actor,miscellaneous\n3                                 actor\n4                       cinematographer\n5  director,assistant_director,producer\n6              director,writer,producer\n7                              producer\n8                              producer\n9                 actor,writer,director\n10                    script_department\n                               knownForTitles\n1     tt0047296,tt0053125,tt0348150,tt1837709\n2     tt0423977,tt0112605,tt6294822,tt0131369\n3     tt0050144,tt0249863,tt0223581,tt0244475\n4               tt0057509,tt8157292,tt9066040\n5     tt0156724,tt0156556,tt0156995,tt0156718\n6  tt26241720,tt32591822,tt14358988,tt7075484\n7    tt4493588,tt0051094,tt10250868,tt0048404\n8     tt0141673,tt0094787,tt0101493,tt0075845\n9     tt0312036,tt0054327,tt0048565,tt0048402\n10    tt0039315,tt0038385,tt0036884,tt0037544\n\n\nThis code finds all the people with missing death dates and also filters for and age max of 100. Any list of data with a calculated age more than this not only starts to become unreasonable but also fails to be true after a quick Google search. Using this method we get Eva Marie Saint.\n\n\n\n\nTo answer this we will need to do a couple of join statements.\n\n\nShow the code\nseries_name &lt;- TITLE_EPISODES %&gt;% #allows us to get the name of show,not just episode\n  inner_join(TITLE_BASICS, by = c('parentTconst' = 'tconst')) %&gt;% \n  filter(titleType == \"tvSeries\") %&gt;% \n  select(parentTconst,originalTitle) %&gt;% \n  distinct(parentTconst, .keep_all = TRUE)\n  \nepisodes_ranked &lt;- TITLE_EPISODES %&gt;% \n  left_join(TITLE_BASICS, by = 'tconst') %&gt;% #\n  inner_join(TITLE_RATINGS, by = 'tconst') %&gt;%\n  inner_join(series_name, by = \"parentTconst\") %&gt;% \n  filter(numVotes &gt; 200000 & averageRating == 10) %&gt;% \n  rename(show_name = originalTitle.y)\nepisodes_ranked %&gt;% select(primaryTitle,show_name,averageRating)\n\n\n  primaryTitle    show_name averageRating\n1   Ozymandias Breaking Bad            10\n\n\nUsing the left join in the first statement we can assure that we get the column we need to do the join with series_name data frame and the other inner_join’s allow us to only get the matching data. The answer to this question is no surprise to me being a huge Breaking Bad fan.\n\n\n\n\n\nShow the code\nNAME_BASICS |&gt; \n  separate_longer_delim(knownForTitles, \",\") %&gt;% \n  filter(primaryName == \"Mark Hamill\") %&gt;%\n  inner_join(TITLE_BASICS,by = c('knownForTitles' = 'tconst')) %&gt;% \n  select(primaryName,primaryTitle)\n\n\n  primaryName                                   primaryTitle\n1 Mark Hamill             Star Wars: Episode IV - A New Hope\n2 Mark Hamill        Star Wars: Episode VIII - The Last Jedi\n3 Mark Hamill Star Wars: Episode V - The Empire Strikes Back\n4 Mark Hamill     Star Wars: Episode VI - Return of the Jedi\n\n\nUsing an inner join after separating the known for column into unique cells allows us to see exactly what movies Hamill is best known for. We that it is the original Star wars films.\n\n\n\nAnswering this question requires some more joining as previously done as well as a statement that counts episodes per show and filters based a count greater than 12. Along with this i’ve also applied a dense_rank function. This ranks the averages, while also accounting for shows that have equal rating. The highest ranked shows under these conditions have a 9.7, and you can see from the dense rank the is a few shows with that rating. The interesting part is that Breaking Bad is ranked in 3rd position. I believe this to be because the greater than 12 episodes condition allows some obscure shows to be introduced. Lets change that number to 60 and see the results.\n\n\n\n\nShow the code\ntv_ranked&lt;- TITLE_EPISODES %&gt;%\n   inner_join(TITLE_RATINGS, by = c('parentTconst'='tconst')) %&gt;%\n   inner_join(TITLE_BASICS, by = c('parentTconst' = 'tconst')) %&gt;% \n   group_by(parentTconst) %&gt;% \n   filter(n()&gt;12) %&gt;% \n   ungroup() %&gt;% \n   select(primaryTitle,averageRating) %&gt;%\n   distinct(primaryTitle, .keep_all = TRUE) %&gt;% \n   mutate(rank = dense_rank(desc(averageRating))) %&gt;% \n   arrange(rank)\nDT::datatable(tv_ranked %&gt;% head(35),filter = 'top', options = list(\n  pageLength = 5))\n\n\n\n\n\n\n\n\n\nChanging the count to 60 did not seem to make a significant difference to 20 rows, and the first page as well as, the main answer are unchanged.\n\n\n\n\nThe best way to answer this question is to see the relation graphically. After making the data frame below we can use that to create 2 plots, one to display the average for each episode and one to display the season average for a cleaner distinction of relation.\n\n\nShow the code\nhappy_days&lt;- TITLE_EPISODES %&gt;%\n  inner_join(TITLE_RATINGS, by = c('tconst'='tconst')) %&gt;%\n  inner_join(TITLE_BASICS, by = c('parentTconst' = 'tconst')) %&gt;% \n  filter(primaryTitle == 'Happy Days') %&gt;% \n  mutate(season_episode= str_c(seasonNumber,episodeNumber, sep = \",\")) %&gt;%\n  select(averageRating,season_episode,seasonNumber,episodeNumber) %&gt;% \n  arrange(seasonNumber,episodeNumber) %&gt;% \n  group_by(seasonNumber) %&gt;% \n  mutate(season_average = mean(averageRating))\n\nggplot(happy_days, aes(x = season_episode, y = averageRating)) +\n  geom_point(size = 2.5,color = \"purple\") +\n  labs(title = \"Average Ratings of Happy Days Episodes\",\n       y = \"Average Rating\", x = \"Show Timeline\") +\n  theme_bw() +\n  theme(axis.text.x = element_blank())\n\n\n\n\n\n\n\n\n\nSeems like there might be a downward trend.\n\n\nShow the code\nggplot(happy_days, aes(x = seasonNumber, y = season_average)) +\n  geom_point(size = 2.5, color = \"purple\") +\n  geom_smooth(se = FALSE)+\n  labs(title = \"Average Ratings of Happy Days by Season\",\n       y = \"Seasonal Average Rating\", x = \"Season Number\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nThe above chart shows more clearly that were was a decline in rating as the show went on it was trending upwards towards the last few seasons. This indicates the show runners might have caught on to declining ratings and made changes to account for it. Using an animation we can see how drastic the drop from the trend was.\n\n\nShow the code\nsmooth_vals = predict(loess(season_average~seasonNumber,happy_days))\n \nggplot(happy_days, aes(x = seasonNumber, y = season_average)) +\n  geom_point(size = 4, color = \"purple\") +\n  geom_line(aes(y = smooth_vals, color = \"Predicted Trend\"), linewidth = 2, linetype = 'dotdash') +\n  labs(title = \"Average Ratings of Happy Days by Season\", \n       y = \"Seasonal Average Rating\", \n       x = \"Season Number\", \n       color = \"Legend\") +\n  theme_bw() +\n  transition_reveal(seasonNumber) +\n  ease_aes('linear')+\n   theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "MP02.html#introduction",
    "href": "MP02.html#introduction",
    "title": "Mini Project#2 - Hollywood Analysis",
    "section": "",
    "text": "This project examines trends in IMDb movie data to understand factors influencing film success. It focuses on genre popularity and critical ratings over time, uncovering what makes a successful film project. We can then use this analysis to pitch a new project.\n\n\nSince the data is very large we will need to reduce the size of the data by filtering out the information that is not useful for analysis. We can do this by removing people with less than 2 “known for” title credits and also removing rare movies with less than 100 ratings.\n\n\nShow the code\nlibrary(ggplot2)\nTITLE_RATINGS |&gt;\n    ggplot(aes(x=numVotes)) + \n    geom_histogram(bins=30,fill='blue') +\n    xlab(\"Number of IMDB Ratings\") + \n    ylab(\"Number of Titles\") + \n    ggtitle(\"Majority of IMDB Titles Have Less than 100 Ratings\") + \n    theme_bw() + \n    scale_x_log10(label=scales::comma) + \n    scale_y_continuous(label=scales::comma)\n\n\n\n\n\n\n\n\n\nThe graph above is a great representation of the distribution of the our movie data with number of ratings as a descriptor. Showcases how a significant chunk of our date has a number of ratings that is less than 100.\n\n\n\n\n\nShow the code\nlibrary(stringr)\nlibrary(dplyr)\nNAME_BASICS &lt;- NAME_BASICS |&gt; \n  filter(str_count(knownForTitles, \",\") &gt; 1) #filtering the known for titles\n#removing those titles that have less than 100 ratings\n\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n    filter(numVotes &gt;= 100)\n# now using this to reduced date to filter all the other tables with semi_join \nTITLE_BASICS &lt;- TITLE_BASICS |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(tconst == tconst))\n\nTITLE_CREW &lt;- TITLE_CREW |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(tconst == tconst))\n\nTITLE_EPISODES_1 &lt;- TITLE_EPISODES |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(tconst == tconst))\nTITLE_EPISODES_2 &lt;- TITLE_EPISODES |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(parentTconst == tconst))\n\nTITLE_EPISODES &lt;- bind_rows(TITLE_EPISODES_1,\n                            TITLE_EPISODES_2) |&gt;\n    distinct()\n\nTITLE_PRINCIPALS &lt;- TITLE_PRINCIPALS |&gt;\n    semi_join(TITLE_RATINGS, join_by(tconst == tconst))\n\nrm(TITLE_EPISODES_1)\nrm(TITLE_EPISODES_2)\n\n\nThe code above uses a semi-join to filter the other tables, ensuring that they only retain rows with keys that match those in the initial table without actually joining any tables together.\n\n\n\nMost of the time, data will contain many discrepancies. In the case of this data the source used the character \\\\N to representing a missing value within numeric columns. This raises two problems, firstly R does not recognize \\\\N as null, and the columns that should be numeric are in the string format. We can fix both by using as.numeric , which will convert the columns into numeric and also turn unrecognized strings into NAs.\n\n\nShow the code\n### Cleaning the data ####\nglimpse(TITLE_BASICS)\n\n\nRows: 374,145\nColumns: 9\n$ tconst         &lt;chr&gt; \"tt0000001\", \"tt0000002\", \"tt0000003\", \"tt0000004\", \"tt…\n$ titleType      &lt;chr&gt; \"short\", \"short\", \"short\", \"short\", \"short\", \"short\", \"…\n$ primaryTitle   &lt;chr&gt; \"Carmencita\", \"Le clown et ses chiens\", \"Poor Pierrot\",…\n$ originalTitle  &lt;chr&gt; \"Carmencita\", \"Le clown et ses chiens\", \"Pauvre Pierrot…\n$ isAdult        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ startYear      &lt;chr&gt; \"1894\", \"1892\", \"1892\", \"1892\", \"1893\", \"1894\", \"1894\",…\n$ endYear        &lt;chr&gt; \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\",…\n$ runtimeMinutes &lt;chr&gt; \"1\", \"5\", \"5\", \"12\", \"1\", \"1\", \"1\", \"1\", \"45\", \"1\", \"1\"…\n$ genres         &lt;chr&gt; \"Documentary,Short\", \"Animation,Short\", \"Animation,Come…\n\n\nShow the code\nprint(\"________________\")\n\n\n[1] \"________________\"\n\n\nShow the code\nglimpse(TITLE_EPISODES)\n\n\nRows: 3,022,865\nColumns: 4\n$ tconst        &lt;chr&gt; \"tt0045960\", \"tt0046855\", \"tt0048378\", \"tt0048562\", \"tt0…\n$ parentTconst  &lt;chr&gt; \"tt0044284\", \"tt0046643\", \"tt0047702\", \"tt0047768\", \"tt0…\n$ seasonNumber  &lt;chr&gt; \"2\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"3\", \"3\", \"…\n$ episodeNumber &lt;chr&gt; \"3\", \"4\", \"6\", \"10\", \"4\", \"20\", \"5\", \"2\", \"20\", \"6\", \"2\"…\n\n\nShow the code\nNAME_BASICS &lt;- NAME_BASICS |&gt;\n    mutate(birthYear = as.numeric(birthYear),\n           deathYear = as.numeric(deathYear)) # using the as numeric to force non-numeric into actual N/A instead of the \\\\N.R provides by the data\n\n\nWarning: There were 2 warnings in `mutate()`.\nThe first warning was:\nℹ In argument: `birthYear = as.numeric(birthYear)`.\nCaused by warning:\n! NAs introduced by coercion\nℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n\n\nShow the code\nTITLE_BASICS &lt;- TITLE_BASICS |&gt;\n    mutate(startYear = as.numeric(startYear),\n           endYear = as.numeric(endYear),\n           isAdult = as.logical(isAdult))\n\n\nWarning: There were 2 warnings in `mutate()`.\nThe first warning was:\nℹ In argument: `startYear = as.numeric(startYear)`.\nCaused by warning:\n! NAs introduced by coercion\nℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n\n\nShow the code\nTITLE_EPISODES &lt;- TITLE_EPISODES |&gt;\n    mutate(seasonNumber = as.numeric(seasonNumber),\n           episodeNumber = as.numeric(episodeNumber))\n\n\nWarning: There were 2 warnings in `mutate()`.\nThe first warning was:\nℹ In argument: `seasonNumber = as.numeric(seasonNumber)`.\nCaused by warning:\n! NAs introduced by coercion\nℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n\n\nOur data also contains rows that have multiple values per cell. Separating these into their own rows will allow us to do a more detailed analysis later on. The code below does exactly that.\n\n\nShow the code\nNAME_BASICS |&gt; separate_longer_delim(knownForTitles, \",\") |&gt; slice_head(n=10)\n\n\n      nconst     primaryName birthYear deathYear\n1  nm0000001    Fred Astaire      1899      1987\n2  nm0000001    Fred Astaire      1899      1987\n3  nm0000001    Fred Astaire      1899      1987\n4  nm0000001    Fred Astaire      1899      1987\n5  nm0000002   Lauren Bacall      1924      2014\n6  nm0000002   Lauren Bacall      1924      2014\n7  nm0000002   Lauren Bacall      1924      2014\n8  nm0000002   Lauren Bacall      1924      2014\n9  nm0000003 Brigitte Bardot      1934        NA\n10 nm0000003 Brigitte Bardot      1934        NA\n                    primaryProfession knownForTitles\n1        actor,miscellaneous,producer      tt0050419\n2        actor,miscellaneous,producer      tt0072308\n3        actor,miscellaneous,producer      tt0053137\n4        actor,miscellaneous,producer      tt0027125\n5  actress,soundtrack,archive_footage      tt0037382\n6  actress,soundtrack,archive_footage      tt0075213\n7  actress,soundtrack,archive_footage      tt0117057\n8  actress,soundtrack,archive_footage      tt0038355\n9   actress,music_department,producer      tt0057345\n10  actress,music_department,producer      tt0049189\n\n\n\n\n\n\n\nTo answer this question we can first find out which table provides the answer efficiently. Looking at the tables, TITLE_BASICS seems to contain the most relevant information. By first using the Unique function on the title type column, we can see how best to filter our data to count each category.\n\n\nShow the code\n  unique(TITLE_BASICS$titleType)\n\n\n [1] \"short\"        \"movie\"        \"tvSeries\"     \"tvShort\"      \"tvMovie\"     \n [6] \"tvEpisode\"    \"tvMiniSeries\" \"video\"        \"tvSpecial\"    \"videoGame\"   \n\n\nThis shows us all the categories in the column and how to properly query them without scrolling through hundreds of rows of data. This shows some interesting information like the video game category which you wouldn’t expect to see on a film database\n\n\nShow the code\ncat(\"Number of Movies in Data:\",  TITLE_BASICS %&gt;% filter(titleType == \"movie\") %&gt;% summarise(count = n()) %&gt;% pull(count),\"\\n\") \n\n\nNumber of Movies in Data: 132220 \n\n\nShow the code\ncat(\"Number of TV Series:\", TITLE_BASICS %&gt;% filter(titleType == \"tvSeries\") %&gt;% summarise(count = n()) %&gt;% pull(count),\"\\n\")\n\n\nNumber of TV Series: 29986 \n\n\nShow the code\ncat(\"Number of TV episodes:\", TITLE_BASICS %&gt;% filter(titleType == \"tvEpisode\") %&gt;% summarise(count = n()) %&gt;% pull(count))\n\n\nNumber of TV episodes: 156725\n\n\n\n\n\nIn order to get an accurate answer, and basing it mostly on the data at hand we must use the filter function for living people and getting the minimum birth year that makes sense. This assumes that the death date is in fact accurate and is a death date. Something to note is that at least one group of people is listed in this table, under the name Cherry Bullet with a death date of 2024. This data point is misleading as this is not a single person but a KPOP group, and the death date is the date the band separated.\n\n\nShow the code\nNAME_BASICS %&gt;% filter(is.na(deathYear),!is.na(birthYear), 2024-birthYear &lt;= 100) %&gt;% arrange(birthYear) %&gt;% head(10)\n\n\n      nconst              primaryName birthYear deathYear\n1  nm0001693          Eva Marie Saint      1924        NA\n2  nm0011140                Lee Adams      1924        NA\n3  nm0021786         Humberto Almazán      1924        NA\n4  nm0073561        Yuriy Berenshteyn      1924        NA\n5  nm0080310 Harsukh Jagneshwar Bhatt      1924        NA\n6  nm0084762          Bo Bjelfvenstam      1924        NA\n7  nm0097155            Carola Bornée      1924        NA\n8  nm0106849            Pietro Bregni      1924        NA\n9  nm0121557             Michael Burk      1924        NA\n10 nm0130807          Hillevi Calvert      1924        NA\n                      primaryProfession\n1           actress,producer,soundtrack\n2  music_department,actor,miscellaneous\n3                                 actor\n4                       cinematographer\n5  director,assistant_director,producer\n6              director,writer,producer\n7                              producer\n8                              producer\n9                 actor,writer,director\n10                    script_department\n                               knownForTitles\n1     tt0047296,tt0053125,tt0348150,tt1837709\n2     tt0423977,tt0112605,tt6294822,tt0131369\n3     tt0050144,tt0249863,tt0223581,tt0244475\n4               tt0057509,tt8157292,tt9066040\n5     tt0156724,tt0156556,tt0156995,tt0156718\n6  tt26241720,tt32591822,tt14358988,tt7075484\n7    tt4493588,tt0051094,tt10250868,tt0048404\n8     tt0141673,tt0094787,tt0101493,tt0075845\n9     tt0312036,tt0054327,tt0048565,tt0048402\n10    tt0039315,tt0038385,tt0036884,tt0037544\n\n\nThis code finds all the people with missing death dates and also filters for and age max of 100. Any list of data with a calculated age more than this not only starts to become unreasonable but also fails to be true after a quick Google search. Using this method we get Eva Marie Saint.\n\n\n\n\nTo answer this we will need to do a couple of join statements.\n\n\nShow the code\nseries_name &lt;- TITLE_EPISODES %&gt;% #allows us to get the name of show,not just episode\n  inner_join(TITLE_BASICS, by = c('parentTconst' = 'tconst')) %&gt;% \n  filter(titleType == \"tvSeries\") %&gt;% \n  select(parentTconst,originalTitle) %&gt;% \n  distinct(parentTconst, .keep_all = TRUE)\n  \nepisodes_ranked &lt;- TITLE_EPISODES %&gt;% \n  left_join(TITLE_BASICS, by = 'tconst') %&gt;% #\n  inner_join(TITLE_RATINGS, by = 'tconst') %&gt;%\n  inner_join(series_name, by = \"parentTconst\") %&gt;% \n  filter(numVotes &gt; 200000 & averageRating == 10) %&gt;% \n  rename(show_name = originalTitle.y)\nepisodes_ranked %&gt;% select(primaryTitle,show_name,averageRating)\n\n\n  primaryTitle    show_name averageRating\n1   Ozymandias Breaking Bad            10\n\n\nUsing the left join in the first statement we can assure that we get the column we need to do the join with series_name data frame and the other inner_join’s allow us to only get the matching data. The answer to this question is no surprise to me being a huge Breaking Bad fan.\n\n\n\n\n\nShow the code\nNAME_BASICS |&gt; \n  separate_longer_delim(knownForTitles, \",\") %&gt;% \n  filter(primaryName == \"Mark Hamill\") %&gt;%\n  inner_join(TITLE_BASICS,by = c('knownForTitles' = 'tconst')) %&gt;% \n  select(primaryName,primaryTitle)\n\n\n  primaryName                                   primaryTitle\n1 Mark Hamill             Star Wars: Episode IV - A New Hope\n2 Mark Hamill        Star Wars: Episode VIII - The Last Jedi\n3 Mark Hamill Star Wars: Episode V - The Empire Strikes Back\n4 Mark Hamill     Star Wars: Episode VI - Return of the Jedi\n\n\nUsing an inner join after separating the known for column into unique cells allows us to see exactly what movies Hamill is best known for. We that it is the original Star wars films.\n\n\n\nAnswering this question requires some more joining as previously done as well as a statement that counts episodes per show and filters based a count greater than 12. Along with this i’ve also applied a dense_rank function. This ranks the averages, while also accounting for shows that have equal rating. The highest ranked shows under these conditions have a 9.7, and you can see from the dense rank the is a few shows with that rating. The interesting part is that Breaking Bad is ranked in 3rd position. I believe this to be because the greater than 12 episodes condition allows some obscure shows to be introduced. Lets change that number to 60 and see the results.\n\n\n\n\nShow the code\ntv_ranked&lt;- TITLE_EPISODES %&gt;%\n   inner_join(TITLE_RATINGS, by = c('parentTconst'='tconst')) %&gt;%\n   inner_join(TITLE_BASICS, by = c('parentTconst' = 'tconst')) %&gt;% \n   group_by(parentTconst) %&gt;% \n   filter(n()&gt;12) %&gt;% \n   ungroup() %&gt;% \n   select(primaryTitle,averageRating) %&gt;%\n   distinct(primaryTitle, .keep_all = TRUE) %&gt;% \n   mutate(rank = dense_rank(desc(averageRating))) %&gt;% \n   arrange(rank)\nDT::datatable(tv_ranked %&gt;% head(35),filter = 'top', options = list(\n  pageLength = 5))\n\n\n\n\n\n\n\n\n\nChanging the count to 60 did not seem to make a significant difference to 20 rows, and the first page as well as, the main answer are unchanged.\n\n\n\n\nThe best way to answer this question is to see the relation graphically. After making the data frame below we can use that to create 2 plots, one to display the average for each episode and one to display the season average for a cleaner distinction of relation.\n\n\nShow the code\nhappy_days&lt;- TITLE_EPISODES %&gt;%\n  inner_join(TITLE_RATINGS, by = c('tconst'='tconst')) %&gt;%\n  inner_join(TITLE_BASICS, by = c('parentTconst' = 'tconst')) %&gt;% \n  filter(primaryTitle == 'Happy Days') %&gt;% \n  mutate(season_episode= str_c(seasonNumber,episodeNumber, sep = \",\")) %&gt;%\n  select(averageRating,season_episode,seasonNumber,episodeNumber) %&gt;% \n  arrange(seasonNumber,episodeNumber) %&gt;% \n  group_by(seasonNumber) %&gt;% \n  mutate(season_average = mean(averageRating))\n\nggplot(happy_days, aes(x = season_episode, y = averageRating)) +\n  geom_point(size = 2.5,color = \"purple\") +\n  labs(title = \"Average Ratings of Happy Days Episodes\",\n       y = \"Average Rating\", x = \"Show Timeline\") +\n  theme_bw() +\n  theme(axis.text.x = element_blank())\n\n\n\n\n\n\n\n\n\nSeems like there might be a downward trend.\n\n\nShow the code\nggplot(happy_days, aes(x = seasonNumber, y = season_average)) +\n  geom_point(size = 2.5, color = \"purple\") +\n  geom_smooth(se = FALSE)+\n  labs(title = \"Average Ratings of Happy Days by Season\",\n       y = \"Seasonal Average Rating\", x = \"Season Number\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nThe above chart shows more clearly that were was a decline in rating as the show went on it was trending upwards towards the last few seasons. This indicates the show runners might have caught on to declining ratings and made changes to account for it. Using an animation we can see how drastic the drop from the trend was.\n\n\nShow the code\nsmooth_vals = predict(loess(season_average~seasonNumber,happy_days))\n \nggplot(happy_days, aes(x = seasonNumber, y = season_average)) +\n  geom_point(size = 4, color = \"purple\") +\n  geom_line(aes(y = smooth_vals, color = \"Predicted Trend\"), linewidth = 2, linetype = 'dotdash') +\n  labs(title = \"Average Ratings of Happy Days by Season\", \n       y = \"Seasonal Average Rating\", \n       x = \"Season Number\", \n       color = \"Legend\") +\n  theme_bw() +\n  transition_reveal(seasonNumber) +\n  ease_aes('linear')+\n   theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "MP02.html#task-3",
    "href": "MP02.html#task-3",
    "title": "Mini Project#2 - Hollywood Analysis",
    "section": "Task 3",
    "text": "Task 3"
  },
  {
    "objectID": "MP02.html#task-3-creating-a-metric",
    "href": "MP02.html#task-3-creating-a-metric",
    "title": "Mini Project#2 - Hollywood Analysis",
    "section": "Task 3: Creating a Metric",
    "text": "Task 3: Creating a Metric\nWhen deciding a metric its important to consider both the number of votes and the rating together. At first I thought we could simply do a ratio or multiplication of the two number to get a single value to judge the over all reception of a film, however this would cause some scores to be misleading. For example if we were to multiply the rating and number of votes, and say the higher the number the better, this would lead to some movies with large votes and low ratings to still be ranked relatively high. So to solve this problem I took three steps:\n\nBinning the Votes: The votes have a large number of variance between them, and in order to effectively use this data in a metric it would be best to bin them. I chose 10 bins, effectively making it so that the number of votes will be confined into a range 1-10, with each number having a range of votes similar to a histogram. To do this we use: mutate(vote_bin = ntile(numVotes, n=10))\nTaking the Log of the Scores: At first,I was messing with the idea of using a log to account for the issues previously stated but decided binning the data was best course of action. However, I found that taking the log of these numbers made the score between 0 and 1 thus making it so when we multiply it with the vote bin, a perfect rating had an overall score that was equal to the bin number. So a movie with a 10 average rating and a was in the highest bin(10) had a combined metric equal to 10.\nMultiply the Log of the scores and the Vote Bin: This has the effective stated above. A film with a 10 rating and an sufficiently large number of votes will score an overall rating of 10, which I think makes this metric quite interesting. To make this metric sound fancy and grandiose ill call it the “Cinematic Log Index” .\n1. Choose the top 5-10 movies on your metric and confirm that they were indeed box office successes.\n\n\nShow the code\nTITLE_BASICS &lt;- TITLE_BASICS %&gt;% \n  inner_join(TITLE_RATINGS,by = 'tconst')\n ## creating a metric\npopular_titles &lt;- TITLE_BASICS %&gt;% \n  filter(numVotes &gt; 500)\npopular_titles &lt;- popular_titles %&gt;% mutate(vote_bin = ntile(numVotes, n=10))\npopular_titles &lt;- popular_titles %&gt;% \n  mutate(CLI = log10(averageRating)*vote_bin)\n\npopular_titles %&gt;% \n  select(primaryTitle,CLI) %&gt;% \n  arrange(desc(CLI)) %&gt;% \n  head(10)\n\n\n                         primaryTitle       CLI\n1                          Ozymandias 10.000000\n2                  Everyone's Waiting  9.956352\n3          The View from Halfway Down  9.956352\n4                 End of the Prologue  9.956352\n5  Sozin's Comet, Part 4: Avatar Aang  9.956352\n6                  Plan and Execution  9.956352\n7                            Face Off  9.956352\n8                    Connor's Wedding  9.956352\n9              The Rains of Castamere  9.956352\n10                             Felina  9.956352\n\n\n\nThe results show the Breaking Bad episode being number 1 and a number of extremely popular TV programs following, including Avatar, Succession, Bojack Horseman, Six Feet Under, and Game of Thrones. Lets filter for movies and see the results.\n\n\nShow the code\n popular_titles %&gt;% \n   filter(titleType == \"movie\") %&gt;% \n   select(primaryTitle,CLI) %&gt;% \n  arrange(desc(CLI)) %&gt;% \n  head(10)\n\n\n                                    primaryTitle      CLI\n1                       The Shawshank Redemption 9.684829\n2                                  The Godfather 9.637878\n3                                The Chaos Class 9.637878\n4            Ramayana: The Legend of Prince Rama 9.637878\n5                                   12 Angry Men 9.542425\n6                          The Godfather Part II 9.542425\n7                               Schindler's List 9.542425\n8  The Lord of the Rings: The Return of the King 9.542425\n9                                The Dark Knight 9.542425\n10                                         Kaiva 9.542425\n\n\nAs you can see these are some of the best movies of all time including The Godfather, 12 Angry Men, and the Lord of the Rings and The Dark Knight in the 8th and 9th positions.\n\n2. Choose 3-5 movies with large numbers of IMDb votes that score poorly on your success metric and confirm that they are indeed of low quality.\n\n\nShow the code\n popular_titles %&gt;% \n  select(primaryTitle,CLI,vote_bin) %&gt;% \n  arrange(desc(vote_bin),CLI) %&gt;% \n  head(10)\n\n\n                     primaryTitle       CLI vote_bin\n1                            Reis 0.0000000       10\n2  Cumali Ceber: Allah Seni Alsin 0.0000000       10\n3                  The Pogmentary 0.4139269       10\n4                     Golden Bull 0.4139269       10\n5                The Last Pharaoh 0.4139269       10\n6               Daniel the Wizard 0.7918125       10\n7            15/07: Break of Dawn 0.7918125       10\n8                 Queen Cleopatra 0.7918125       10\n9                        Smolensk 0.7918125       10\n10                        Sadak 2 0.7918125       10\n\n\nAs you can see this query returns a handful of garbage films like “The Pogmentary”, which has articles calling it the worst TV show or Movie on IMDB of all time.\n\n\n3. Choose a prestige actor or director and confirm that they have many projects with high scores on your success metric.\n\n\nShow the code\nNAMES &lt;- NAME_BASICS |&gt; \n  separate_longer_delim(knownForTitles, \",\") %&gt;% \n  select(knownForTitles,primaryName)\n\npopular_titles &lt;-popular_titles %&gt;%\n  inner_join(NAMES,by=c('tconst'='knownForTitles')) \n  \n#popular_titles = select(popular_titles,-10,-11,-12,-13)\n\n(popular_titles %&gt;% \n  filter(primaryName =='Robert De Niro') %&gt;% \n  select(primaryName,CLI,averageRating,primaryTitle))\n\n\n     primaryName      CLI averageRating    primaryTitle\n1 Robert De Niro 9.138139           8.2     Taxi Driver\n2 Robert De Niro 9.084850           8.1 The Deer Hunter\n3 Robert De Niro 9.084850           8.1     Raging Bull\n4 Robert De Niro 8.633229           7.3       Cape Fear\n\n\nLooks like the CLI works for popular actors as well. You can see that taking the vote bin into account the CLI is actually higher than the average rating.\n\n\nPerform at least one other form of ‘spot check’ validation.\nLets check two popular Ben Affleck movies both known for their “quality”.\n\n\nShow the code\npopular_titles %&gt;%\n  filter(primaryTitle == \"Gigli\"|primaryTitle == 'Good Will Hunting') %&gt;% \n  select(CLI,primaryTitle,vote_bin) %&gt;% \n  distinct(primaryTitle,.keep_all = TRUE)\n\n\n       CLI      primaryTitle vote_bin\n1 9.190781 Good Will Hunting       10\n2 4.149733             Gigli       10\n\n\nThe CLI score works as expected here.\n\n\n5. Come up with a numerical threshold for a project to be a ‘success’; that is, determine a value v such that movies above v are all “solid” or better.\nBased on the results below, and a confirmation with Google, 8 seems to be a great threshold.\n\n\nShow the code\npopular_titles %&gt;%\n  filter(CLI &gt;= 8 & startYear &gt; 2000) %&gt;% \n  select(CLI,primaryTitle,vote_bin) %&gt;% \n  arrange(CLI) %&gt;% \n  distinct(primaryTitle,.keep_all = TRUE) %&gt;% \n  head(10)\n\n\n        CLI    primaryTitle vote_bin\n1  8.028851           Baran        9\n2  8.028851          Doom 3        9\n3  8.028851        John Doe        9\n4  8.028851           Oasis        9\n5  8.028851  Soldier's Girl        9\n6  8.028851   Fruits Basket        9\n7  8.028851 Innocent Voices        9\n8  8.028851 Live and Become        9\n9  8.028851   Riding Giants        9\n10 8.028851           Simon        9\n\n\n\n\nTask 4: Trends in Success Over Time\n\nWhat was the genre with the most “successes” in each decade?\nLets start by first filtering to get decades that are more recent by filtering for greater than 1959. Than we can use floor divide to get the decades , followed by using summarise and slice_max to get highest count in each decade.\n\n\nShow the code\nrecent &lt;- popular_titles %&gt;% \n  filter(startYear &gt; 1959) %&gt;% \n  mutate(decade = floor(as.numeric(startYear) / 10) * 10)\n\ndecade &lt;- recent %&gt;%\n  filter(CLI &gt; 8) %&gt;% \n  separate_longer_delim(genres, \",\") %&gt;% \n  group_by(decade,genres) %&gt;% \n  summarise(num_success = n()) %&gt;% \n  slice_max(num_success) %&gt;% \n  select(num_success,decade,genres) %&gt;% \n  arrange(decade)\n\n\n`summarise()` has grouped output by 'decade'. You can override using the\n`.groups` argument.\n\n\nShow the code\ndecade\n\n\n# A tibble: 7 × 3\n# Groups:   decade [7]\n  num_success decade genres\n        &lt;int&gt;  &lt;dbl&gt; &lt;chr&gt; \n1        2441   1960 Drama \n2        3724   1970 Drama \n3        8096   1980 Drama \n4       20001   1990 Drama \n5       20697   2000 Drama \n6       14844   2010 Drama \n7        3121   2020 Drama \n\n\nSeem to be getting drama for each one based on my metric, most likely because drama alongside many other genres.\n\n\nWhat genre consistently has the most “successes”? What genre used to reliably produced “successes” and has fallen out of favor?\nFrom the results above you can see drama is very consistent however, this could be inaccurate due to many different genres also being labeled with genre.\n\n\nWhat genre has produced the most “successes” since 2010? Does it have the highest success rate or does it only have a large number of successes because there are many productions in that genre?\nWe can see from above that the drama genre has the highest number in 2010, but does it have a good success rate?\n\n\nShow the code\nrecent %&gt;% \n  filter(decade== 2010) %&gt;% \n  separate_longer_delim(genres, \",\") %&gt;% \n  group_by(genres) %&gt;% \n  mutate(total_n_genre = n()) %&gt;% #total rows per genre\n  filter(CLI &gt; 8) %&gt;%\n  mutate(success_rate = n() / total_n_genre) %&gt;% \n  select(genres,decade,success_rate)\n\n\n# A tibble: 65,752 × 3\n# Groups:   genres [26]\n   genres    decade success_rate\n   &lt;chr&gt;      &lt;dbl&gt;        &lt;dbl&gt;\n 1 Adventure   2010        0.623\n 2 Comedy      2010        0.470\n 3 Drama       2010        0.578\n 4 Adventure   2010        0.623\n 5 Comedy      2010        0.470\n 6 Drama       2010        0.578\n 7 Adventure   2010        0.623\n 8 Comedy      2010        0.470\n 9 Drama       2010        0.578\n10 Adventure   2010        0.623\n# ℹ 65,742 more rows\n\n\nBased on success rate the Adventure genre is actually the best for the 2010 decade.\n\n\nWhat genre has become more popular in recent years?\n\n\nShow the code\nrate_2020 &lt;-recent %&gt;% \n  filter(decade== 2020) %&gt;% \n  separate_longer_delim(genres, \",\") %&gt;% \n  group_by(genres) %&gt;% \n  mutate(total_n_genre = n()) %&gt;% #total rows per genre\n  filter(CLI &gt; 8) %&gt;%\n  mutate(success_rate = n() / total_n_genre) %&gt;% \n  select(genres,decade,success_rate)\n\nggplot(rate_2020,aes(x = genres,y=success_rate,fill = genres))+ \n  geom_bar(stat = 'identity')+\n  theme_bw()+\n  theme(axis.text.x = element_text(angle = 45,hjust= 1))+\n  theme(legend.position =\"none\")+\n  labs(title = \"2020 Success Rate By Genres\", y ='Rate',x= \"Genre\")\n\n\n\n\n\n\n\n\n\n\n\n\nTask 5: Key Personnel\nBased on the on some previous analysis I have already decided to pick one of the actors as Robert De Niro. The other actor will need to be found through some more analysis.\n\n\nShow the code\nrecent &lt;- popular_titles %&gt;% \n  filter(startYear &gt; 1959) %&gt;%\n  mutate(decade = floor(as.numeric(startYear) / 10) * 10)\n\nrecent %&gt;% \n  filter(startYear &gt; 2022) %&gt;% \n  select(primaryName,genres,CLI) %&gt;% \n  arrange(desc(CLI)) %&gt;% \n  head(10)\n\n\n          primaryName                     genres      CLI\n1     Chad Birmingham        Crime,Drama,Fantasy 9.444827\n2       François Chau        Crime,Drama,Fantasy 9.444827\n3        Chase Conley Action,Adventure,Animation 9.444827\n4  Vidhu Vinod Chopra            Biography,Drama 9.444827\n5      Vikram Chandra            Biography,Drama 9.444827\n6      Myron Nettinga Action,Adventure,Animation 9.395193\n7     Haven Alexander Action,Adventure,Animation 9.395193\n8       Andrew Moreau     Action,Adventure,Drama 9.395193\n9     Scott Augustine     Action,Adventure,Drama 9.395193\n10       Pedro Pascal     Action,Adventure,Drama 9.395193\n\n\nHere I see a familiar name, Pedro Pascal. With this new information I will choose Pedro Pascal, Robert De Niro and pair them with original director Martin Scorsese. The choice of these people is based on their household name status, and the metric I’ve designed where they all score very well, &gt; 9.\n\n\nTask 6: Finding a Classic Movie to Remake\nBased on the above results and the some previous analysis I will choose to remake the movie Raging Bull including Robert De Niro as Fan service, staring Pedro Pascal in the main role. This movie and key people have large number of reviews, great ratings, and great CLI’s.\n\n\nTask 7: Pitch\nIn the new age of cinema we see that often the box office is dominated by massively expensive yet emotionally and artistically deprived pieces of work that have started to bore much of the audience. With every movie trying to become the next action filled, 8 part marvel universe movie we have the opportunity to take a step back and release a film that satisfies critiques, fans of film, and introduce a classic to the younger generation. I purpose we take the class film Raging Bull and remake it, staring Pedro Pascal and of course De Niro. Lets get into some of benefits doing this remake.\nSuccess Metric:\nBased on success metric that takes into account both number of ratings and the Average IMDB rating the, original movie as well as the people involved all have very high scores. This metric is called the CLI. Lets take a look at the peoples scores.\n\n\nShow the code\nrecent %&gt;% \n  select(primaryName,CLI) %&gt;% \n  filter(primaryName %in% c('Robert De Niro', 'Pedro Pascal',\"Martin Scorsese\") & CLI &gt; 9) %&gt;% \n  distinct(primaryName,.keep_all = TRUE) %&gt;% \n  arrange(desc(CLI))\n\n\n      primaryName      CLI\n1    Pedro Pascal 9.637878\n2  Robert De Niro 9.138139\n3 Martin Scorsese 9.138139\n\n\nWe can see that they have all been part of productions that both very popular and very good.\nRapid Rise of Dramatic Films:\nWe know that the most popular film genre is the drama genre. However this genre is could also be saturated, so why not choose something like action. According to Investopedia the cost of some action films cost over 200 million dollars like Spider-man 2, Avatar, and many others. This begs the question does it really make sense to make another action film at such a high cost, when drama is much more affordable and the rise is so rapid. See the rise of the drama genre below.\n\n\nShow the code\ndramas &lt;- recent %&gt;%\n  separate_longer_delim(genres, \",\") %&gt;%\n  filter(genres == \"Drama\") %&gt;%\n  group_by(decade) %&gt;%\n  summarise(avg_CLI = mean(CLI, na.rm = TRUE)) %&gt;%  \n  distinct(decade, .keep_all = TRUE)\n\nggplot(dramas, aes(x = decade, y = avg_CLI)) +\n  geom_line(color = \"darkorange\",size = .7,alpha = .5) +\n  geom_point(shape = 24,fill = \"yellow\", size = 3)+\n  theme_bw() +\n  labs(x = \"Time\", y = \"Cinematic Log Index Average\") +\n  ggtitle(\"Rapid Increase of Drama Films\")+\n  transition_reveal(decade)\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n\n\n\n\n\n\n\n\n\nSuccess Prone Cast:\nOne of the biggest reasons, if not the most important reason I am sure this movie will be a success if the cast. The cast contains two legends of the industry De Niro and Scorsese. Along with them Ive chosen a newer actor is extremely well received. Lets take a look at the sucess rate of the 3 of them.\n\n\nShow the code\ncast_success&lt;- recent %&gt;%\n  filter(primaryName %in% c('Robert De Niro', 'Pedro Pascal',\"Martin Scorsese\")) %&gt;% \n  group_by(primaryName) %&gt;%\n  distinct(primaryTitle,.keep_all = TRUE) %&gt;% \n  mutate(num_proj = n()) %&gt;% \n  filter(CLI &gt;= 8) %&gt;% \n  mutate(success_rate =n()/num_proj) %&gt;% \n  select(primaryTitle,primaryName,CLI,success_rate)\ncast_success\n\n\n# A tibble: 12 × 4\n# Groups:   primaryName [3]\n   primaryTitle                primaryName       CLI success_rate\n   &lt;chr&gt;                       &lt;chr&gt;           &lt;dbl&gt;        &lt;dbl&gt;\n 1 Mean Streets                Martin Scorsese  8.57            1\n 2 Taxi Driver                 Robert De Niro   9.14            1\n 3 Taxi Driver                 Martin Scorsese  9.14            1\n 4 The Deer Hunter             Robert De Niro   9.08            1\n 5 Raging Bull                 Robert De Niro   9.08            1\n 6 Goodfellas                  Martin Scorsese  9.40            1\n 7 Cape Fear                   Robert De Niro   8.63            1\n 8 Game of Thrones             Pedro Pascal     9.64            1\n 9 The Last of Us              Pedro Pascal     9.40            1\n10 Kingsman: The Golden Circle Pedro Pascal     8.26            1\n11 Killers of the Flower Moon  Martin Scorsese  8.81            1\n12 The Mandalorian             Pedro Pascal     9.34            1\n\n\nQuite amazing, based on this CLI &gt; 8 metric of success, and of all the titles in the in the known for section the selected cast has a 100% success rate.\nClassic Cliche Trailer:\nFrom director Martin Scorsese, the visionary behind Goodfellas, Taxi Driver, and many more iconic films;\nFrom actor Robert De Niro, the beloved star of Taxi Driver and The Deer Hunter;\nFrom actor Pedro Pascal, Hollywood’s celebrated icon of the drama genre;\nComes the timeless re imagining, Raging Bull—a story of ambition, sacrifice, and redemption.\nComing soon to a theater near you."
  },
  {
    "objectID": "MP03.html",
    "href": "MP03.html",
    "title": "Political Analysis",
    "section": "",
    "text": "In this analysis, in honor of election season this year we will take a look at some trends in the political landscape of the United States. in order to do this we will need some reliable data sources on which we can base out analysis. This includes historical election results and also, some cruical shape files for visualizations. Sources include the MIT election lab as well US Census TIGER shape files.\n\n\nIn order to properly and effecently work with the data we must automate the download process, considering there a mulitple files that need to downloaded. Using a for loop and using the variable format method sprintf we can automate the download of each file dynamically accounting for i. In the second download we use if else statements to account for the changes in the URLs.\n\n\nCode\n### DATA ONE \nhouse_votes &lt;- read_csv(\"1976-2022-house (1).csv\")\n\n\nRows: 32452 Columns: 20\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (7): state, state_po, office, stage, candidate, party, mode\ndbl (8): year, state_fips, state_cen, state_ic, district, candidatevotes, to...\nlgl (5): runoff, special, writein, unofficial, fusion_ticket\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\npres &lt;- read_csv(\"1976-2020-president.csv\")\n\n\nRows: 4287 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): state, state_po, office, candidate, party_detailed, party_simplified\ndbl (7): year, state_fips, state_cen, state_ic, candidatevotes, totalvotes, ...\nlgl (2): writein, notes\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\n### DATA TWO CONGRESSIONAL BOUNDRIES\nlibrary(httr)\nfor (i in 94:112) {\n  BASE_URL &lt;- \"https://cdmaps.polisci.ucla.edu/shp/\"\n  zip_file &lt;- paste0(\"districts\", sprintf(\"%03d\", i), \".zip\")  # Adjusts the format to three digits\n  # Check if file exists\n  if (!file.exists(zip_file)) {\n    FILE_URL &lt;- paste0(BASE_URL, zip_file)\n    print(FILE_URL)\n    # download\n    download.file(FILE_URL, destfile = zip_file,mode = \"wb\")  # Use appropriate method if needed\n    \n  }\n}\n\n\n\n\nCode\nfor (i in 2014:2022) {\n  BASE_URL &lt;- \"https://www2.census.gov/geo/tiger/\"\n  if (i &gt;= 2018) { #### accounting for changes in the cd#\n    file &lt;- paste0(\"TIGER\", sprintf(\"%d\", i), \"/CD/tl_\", sprintf(\"%d\", i), \"_us_cd116.zip\")\n  } else if (i &gt; 2015) {\n    file &lt;- paste0(\"TIGER\", sprintf(\"%d\", i), \"/CD/tl_\", sprintf(\"%d\", i), \"_us_cd115.zip\")\n  } else {\n    file &lt;- paste0(\"TIGER\", sprintf(\"%d\", i), \"/CD/tl_\", sprintf(\"%d\", i), \"_us_cd114.zip\")\n  }\n  download_name &lt;- paste0(\"TIGER\",sprintf(\"%d\",i),\".zip\")\n  # Check if file exists\n  if (!file.exists(download_name)) {\n    FILE_URL &lt;- paste0(BASE_URL,file)\n    print(FILE_URL)\n    # download\n    download.file(FILE_URL, destfile = download_name,mode = \"wb\")\n  }\n}\n\n\n\n\n\nIn this task we take a look at how the number of seats change over time for the states. This is an interesting analysis as it also points to how the population of a state changes over time, from 1976 to 2022. You can see below that Texas gains the most seats, and New York lost the most amount of seats.\nIn addition to this I’ve also included a plot to show how the number of seats for each party changes across time. Interestingly, the trends in the changes of party reflect the recent election, and in some cases the political shift.\n\n\nCode\nseats_won &lt;- house_votes %&gt;%\n  group_by(state, year,district) %&gt;%\n  slice_max(candidatevotes,n = 1) %&gt;% \n  select(year,state,district,party, candidate,candidatevotes)\n\n### TASK 3 PARTY CHANGES AND SEAT CHANGE \nlibrary(ggthemes)\nhouse_votes %&gt;% group_by(year,state) %&gt;% \n  mutate(num_seats = n_distinct(district)) %&gt;%#couting the seats via district\n  ungroup() %&gt;% \n  select(year,state,num_seats) %&gt;%\n  filter(year== 2022 |year ==1976) %&gt;%\n  group_by(state) %&gt;% \n  mutate(diff_seats = num_seats - lag(num_seats)) %&gt;% # subtracting the newer value from the older via lag function\n  filter(year==2022) %&gt;% # this gives up the \"lagged\" values since the older values will not have a diff via the lag method\n  distinct() %&gt;% \n  arrange(desc(abs(diff_seats))) %&gt;% #ordering by biggest differece by absoulte value\n  head(25) %&gt;% \n  #ploting above\n  ggplot(aes(x = state,y = diff_seats,fill = state))+\n  geom_bar(stat = \"identity\",width = 1)+\n  theme_clean()+\n  theme(legend.position = \"FALSE\")+\n  labs(title= \"Changes in Seats of the House of Representatives by State\", \n       x= \"State\", y = \"Change in Seats\")+\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(ggthemes)\n\nseats_won %&gt;% group_by(year,party) %&gt;%\n  drop_na() %&gt;% \n  mutate(party_seats = n()) %&gt;% \n  ggplot(aes(x = year,y = party_seats,color = party))+\n  scale_color_manual(\n    values= c(\"DEMOCRAT\" = \"blue\",\"REPUBLICAN\"= \"red\",\n            \"DEMOCRATIC-FARMER-LABOR\"= \"darkgreen\",\"INDEPENDENT\"=\"lightblue\"))+\n  geom_line(linewidth = 1.2)+\n  theme_minimal()+\n  theme(legend.position = \"bottom\",legend.text = element_text(size = 5))+\n  labs(title = \"Party Seats by Year \", x = \"Year\", y= \"Number of Seats \", color = \"Party\")\n\n\n\n\n\n\n\n\n\n\n\n\nIn the state of New York, there is a fusion ticket system that allows for candidates to be put under more than one party line. This creates an interesting dynamic that allows for candidates to win even though they did not have the max number of votes in their respective parties. We see below that as a matter a fact, multiple times the candidate with the highest single party votes does not always win due to the fusion system.\n\n\nCode\nfusion &lt;- house_votes %&gt;% \n  filter(fusion_ticket == TRUE & candidate != \"BLANK\") %&gt;% \n  select(year,candidate,candidatevotes,district,party,totalvotes) %&gt;% \n  group_by(year,district,candidate) %&gt;% \n  mutate(total_fusion_votes =sum(candidatevotes)) %&gt;% \n  ungroup() %&gt;% \n  group_by(year,district) %&gt;% \n  mutate(highest_single_party_votes = candidate[which.max(candidatevotes)]) %&gt;% \n  ungroup()\n \nfusion_winners &lt;- fusion %&gt;%\n  group_by(year,district) %&gt;% \n  mutate(district_winner = candidate[which.max(total_fusion_votes)]) %&gt;%\n  select(year,district,district_winner,highest_single_party_votes) %&gt;% \n  filter(district_winner!=highest_single_party_votes) %&gt;% \n  distinct() %&gt;% \n  DT::datatable()\nfusion_winners\n\n\n\n\n\n\n\n\n\nHere we answer the question of whether or not there is a difference in votes in the congressional candidate and the presidential candidate of the same party. In this analysis I found certain cases where the congressional candidates had slightly more votes than the presidential, however the average difference across the years has actually been increasing.\n\n\nCode\nhouse_winners &lt;- house_votes %&gt;% \n  group_by(year,district,state,candidate) %&gt;% \n  mutate(cong_votes=sum(candidatevotes)) %&gt;% \n  ungroup %&gt;% group_by(year,district,state) %&gt;% \n  mutate(cong_winner = candidate[which.max(cong_votes)]) %&gt;% ungroup() %&gt;% \n  filter(cong_winner == candidate) %&gt;% \n  select(year,party,state,state_fips,district,cong_votes,cong_winner) %&gt;% \n  ungroup()\n\n \npres %&gt;% \n  inner_join(house_winners, by = c(\"state_fips\",\"party_detailed\" = \"party\",\"state\",\"year\")) %&gt;% \n  group_by(state,candidate,year,cong_winner) %&gt;% \n  mutate(vote_diff = candidatevotes - cong_votes) %&gt;% \n  ungroup() %&gt;% group_by(year) %&gt;%  \n  mutate(avg_diff = mean(vote_diff)) %&gt;% \n  select(year,state,state_fips,party_detailed,candidate,cong_winner,district,vote_diff,avg_diff) %&gt;% \n  ggplot(aes(x = year, y = avg_diff))+\n  geom_line(linewidth = 1.2, color = \"red\")+\n  theme_minimal()+\n  labs(title = \"Average Difference Between Congressional Candidate Votes & Presidential Votes\",\n       x = \"Year\", y = \"Average Difference\")\n\n\n\n\n\n\n\n\n\n\n\n\nWhen it is necessary to repeat a process over and over again it might be beneficial to create a function that is written once and can be used quickly again, or even automated. In this case we will make a function that can take any zip file, and receive its shape file. See below with a download and unzip along with a quick plot of the boroughs.\n\n\nCode\nlibrary(sf)\n\n\nWarning: package 'sf' was built under R version 4.3.3\n\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\n\nCode\nif(!file.exists(\"nyc_borough_boundaries.zip\")){\n    download.file(\"https://data.cityofnewyork.us/api/geospatial/tqmj-j8zm?method=export&format=Shapefile\", \n              destfile=\"nyc_borough_boundaries.zip\")\n}\n\n##-\nunzip_shape &lt;- function(filename){\n \n  dest_dir &lt;- tempdir()\n  file &lt;- unzip(zipfile = filename,exdir = dest_dir)\n  shp_file &lt;- file[grepl(\"\\\\.shp$\",file)]\n  sf &lt;- read_sf(shp_file)\n  return(sf)\n}\n### UNZIPPIING AND PLOTTING\nnyc_sf &lt;- unzip_shape(\"nyc_borough_boundaries.zip\")\n\nggplot(nyc_sf,\n       aes(geometry=geometry,\n           fill = shape_area)) +\n    geom_sf()+\n  theme_void()\n\n\n\n\n\n\n\n\n\n\n\n\nUsing some of the methods previously stated and a new method I will introduce shortly we can plot the US election of 2000, which many consider to be a very controversial election.\nThis new method involves using a cowplot that allows us to ggdraw multiple different plots over each other. This will be very beneficial when plotting the US because the geographic locations of Hawaii and Alaska make a simple plot extremely ugly. This process involves filtering out the 2 states and creating a “main” plot as seen in the code below, and then plotting those 2 states separately. Once this is done we can use the ggdraw function to join them all together and tinker with the x, y, width, and height to get a nice looking plot (note: 0 is the center)\n\n\nCode\nlibrary(tools)\nbushVgore &lt;- unzip_shape(\"tl_2023_us_state.zip\")\n\n# ggplot(bushVgore, \n#        aes(geometry=geometry)) + \n#     geom_sf()\n\nbushVgore &lt;- bushVgore %&gt;% select(NAME,geometry)\n\nelection_2000 &lt;- pres %&gt;% \n  filter(year == 2000 & candidate == \"BUSH, GEORGE W.\"| candidate==\"GORE, AL\") %&gt;% \n  mutate(state = toTitleCase(tolower(state))) %&gt;% \n  select(state,state_po,candidate,candidatevotes,state_fips,totalvotes) %&gt;% \n  inner_join(bushVgore, by = c(\"state\"=\"NAME\")) %&gt;% \n  group_by(state) %&gt;% \n  mutate(state_winner = candidate[which.max(candidatevotes)])\ncolor &lt;- c(\"BUSH, GEORGE W.\" = \"red\",\"GORE, AL\"=\"blue\")\nmain_land &lt;- election_2000 %&gt;% \n  filter(!state %in% c(\"Hawaii\", \"Alaska\")) %&gt;% \n  ggplot(aes(geometry = geometry, fill = state_winner)) +\n  scale_fill_manual(values = color) + \n  geom_sf() +\n  labs(fill = \"Candidate\") + \n  geom_sf_text(aes(label = state_po), size = 1, color = \"white\",fontface = \"bold\")+\n  theme_void()\n#main_land\n\nhawaii &lt;- election_2000 %&gt;% filter(state == \"Hawaii\") %&gt;% \n  ggplot(aes(geometry = geometry,fill = state_winner))+\n  scale_fill_manual(values = color)+\n  geom_sf()+\n  labs(fill = \"Candidate\") +\n   coord_sf(crs = st_crs(4326)) +\n  theme_void()+\n  geom_sf_text(aes(label = state_po), size = 1, color = \"white\",fontface = \"bold\")+\n  theme(legend.position = \"FALSE\")\n#hawaii\n\nalaska &lt;- election_2000 %&gt;%  filter(state ==\"Alaska\") %&gt;% \n  ggplot(aes(geometry = geometry,fill = state_winner))+\n  scale_fill_manual(values = color)+\n  geom_sf()+\n  labs(fill = \"Candidate\") +\n    coord_sf(crs = st_crs(4326)) +\n  theme_void()+\n  geom_sf_text(aes(label = state_po), size = 2, color = \"white\",fontface = \"bold\")+\n  theme(legend.position = \"FALSE\")\n#alaska\n\n# library(parallel)\n# options(mc.cores = NULL)\n\nlibrary(cowplot)\n\n\n\nAttaching package: 'cowplot'\n\n\nThe following object is masked from 'package:ggthemes':\n\n    theme_map\n\n\nThe following object is masked from 'package:lubridate':\n\n    stamp\n\n\nCode\nlibrary(gganimate)\nggdraw()+\n  draw_plot(main_land)+\n  draw_plot(hawaii, x= .1,width = 0.15, height = 0.15)+\n  draw_plot(alaska,y = -.25)\n\n\n\n\n\n\n\n\n\n\n\n\nIn this task we can use the tmap package to create an animated plot of party changes across time. For simplicity sake I have left out the 2 states previously mentioned (my apologizes to the Alaskans and Hawaiians).\n\n\nCode\nlibrary(tools)\nparties &lt;- pres %&gt;%\n  mutate(state = toTitleCase(tolower(state))) %&gt;% \n  filter(state !=\"Hawaii\" & state != \"Alaska\" & year &gt;= 2008) %&gt;% \n  inner_join(bushVgore, by = c(\"state\"=\"NAME\")) %&gt;% #bushvgore is the shape file\n  group_by(state,year) %&gt;%\n  mutate(state_winner = party_detailed[which.max(candidatevotes)]) %&gt;%\n  ungroup()\n\n### facetmap\nlibrary(tmap)\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nCode\n###ANIMATING THE FACET\nanim &lt;- parties %&gt;% \n  filter(year &gt;= 2000) %&gt;% \n  st_as_sf() %&gt;% \n  tm_shape() +\n  tm_polygons(\"state_winner\", title = \"Party\", \n              palette = c(\"REPUBLICAN\" = \"red\", \n                          \"DEMOCRAT\" = \"blue\",\n                          \"DEMOCRATIC-FARMER-LABOR\" = \"lightblue\")) +\n  tm_facets(along = \"year\", free.coords = FALSE)+\n  tm_text(\"state_po\", size = .3, col = \"white\", fontface = \"bold\")\n \n tmap_animation(anim, delay = 50,\"anim_map.gif\")\n\n\nCreating frames\n\n\n========================================\n\n\n====================\n\n\n====================\n\n\n\nCreating animation\nAnimation saved to /Users/harry/R/Project_0/anim_map.gif \n\n\nCode\nknitr::include_graphics(\"anim_map.gif\")"
  },
  {
    "objectID": "MP03.html#set-up-and-initial-exploration",
    "href": "MP03.html#set-up-and-initial-exploration",
    "title": "Political Analysis",
    "section": "",
    "text": "In this analysis, in honor of election season this year we will take a look at some trends in the political landscape of the United States. in order to do this we will need some reliable data sources on which we can base out analysis. This includes historical election results and also, some cruical shape files for visualizations. Sources include the MIT election lab as well US Census TIGER shape files.\n\n\nIn order to properly and effecently work with the data we must automate the download process, considering there a mulitple files that need to downloaded. Using a for loop and using the variable format method sprintf we can automate the download of each file dynamically accounting for i. In the second download we use if else statements to account for the changes in the URLs.\n\n\nCode\n### DATA ONE \nhouse_votes &lt;- read_csv(\"1976-2022-house (1).csv\")\n\n\nRows: 32452 Columns: 20\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (7): state, state_po, office, stage, candidate, party, mode\ndbl (8): year, state_fips, state_cen, state_ic, district, candidatevotes, to...\nlgl (5): runoff, special, writein, unofficial, fusion_ticket\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\npres &lt;- read_csv(\"1976-2020-president.csv\")\n\n\nRows: 4287 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): state, state_po, office, candidate, party_detailed, party_simplified\ndbl (7): year, state_fips, state_cen, state_ic, candidatevotes, totalvotes, ...\nlgl (2): writein, notes\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\n### DATA TWO CONGRESSIONAL BOUNDRIES\nlibrary(httr)\nfor (i in 94:112) {\n  BASE_URL &lt;- \"https://cdmaps.polisci.ucla.edu/shp/\"\n  zip_file &lt;- paste0(\"districts\", sprintf(\"%03d\", i), \".zip\")  # Adjusts the format to three digits\n  # Check if file exists\n  if (!file.exists(zip_file)) {\n    FILE_URL &lt;- paste0(BASE_URL, zip_file)\n    print(FILE_URL)\n    # download\n    download.file(FILE_URL, destfile = zip_file,mode = \"wb\")  # Use appropriate method if needed\n    \n  }\n}\n\n\n\n\nCode\nfor (i in 2014:2022) {\n  BASE_URL &lt;- \"https://www2.census.gov/geo/tiger/\"\n  if (i &gt;= 2018) { #### accounting for changes in the cd#\n    file &lt;- paste0(\"TIGER\", sprintf(\"%d\", i), \"/CD/tl_\", sprintf(\"%d\", i), \"_us_cd116.zip\")\n  } else if (i &gt; 2015) {\n    file &lt;- paste0(\"TIGER\", sprintf(\"%d\", i), \"/CD/tl_\", sprintf(\"%d\", i), \"_us_cd115.zip\")\n  } else {\n    file &lt;- paste0(\"TIGER\", sprintf(\"%d\", i), \"/CD/tl_\", sprintf(\"%d\", i), \"_us_cd114.zip\")\n  }\n  download_name &lt;- paste0(\"TIGER\",sprintf(\"%d\",i),\".zip\")\n  # Check if file exists\n  if (!file.exists(download_name)) {\n    FILE_URL &lt;- paste0(BASE_URL,file)\n    print(FILE_URL)\n    # download\n    download.file(FILE_URL, destfile = download_name,mode = \"wb\")\n  }\n}\n\n\n\n\n\nIn this task we take a look at how the number of seats change over time for the states. This is an interesting analysis as it also points to how the population of a state changes over time, from 1976 to 2022. You can see below that Texas gains the most seats, and New York lost the most amount of seats.\nIn addition to this I’ve also included a plot to show how the number of seats for each party changes across time. Interestingly, the trends in the changes of party reflect the recent election, and in some cases the political shift.\n\n\nCode\nseats_won &lt;- house_votes %&gt;%\n  group_by(state, year,district) %&gt;%\n  slice_max(candidatevotes,n = 1) %&gt;% \n  select(year,state,district,party, candidate,candidatevotes)\n\n### TASK 3 PARTY CHANGES AND SEAT CHANGE \nlibrary(ggthemes)\nhouse_votes %&gt;% group_by(year,state) %&gt;% \n  mutate(num_seats = n_distinct(district)) %&gt;%#couting the seats via district\n  ungroup() %&gt;% \n  select(year,state,num_seats) %&gt;%\n  filter(year== 2022 |year ==1976) %&gt;%\n  group_by(state) %&gt;% \n  mutate(diff_seats = num_seats - lag(num_seats)) %&gt;% # subtracting the newer value from the older via lag function\n  filter(year==2022) %&gt;% # this gives up the \"lagged\" values since the older values will not have a diff via the lag method\n  distinct() %&gt;% \n  arrange(desc(abs(diff_seats))) %&gt;% #ordering by biggest differece by absoulte value\n  head(25) %&gt;% \n  #ploting above\n  ggplot(aes(x = state,y = diff_seats,fill = state))+\n  geom_bar(stat = \"identity\",width = 1)+\n  theme_clean()+\n  theme(legend.position = \"FALSE\")+\n  labs(title= \"Changes in Seats of the House of Representatives by State\", \n       x= \"State\", y = \"Change in Seats\")+\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(ggthemes)\n\nseats_won %&gt;% group_by(year,party) %&gt;%\n  drop_na() %&gt;% \n  mutate(party_seats = n()) %&gt;% \n  ggplot(aes(x = year,y = party_seats,color = party))+\n  scale_color_manual(\n    values= c(\"DEMOCRAT\" = \"blue\",\"REPUBLICAN\"= \"red\",\n            \"DEMOCRATIC-FARMER-LABOR\"= \"darkgreen\",\"INDEPENDENT\"=\"lightblue\"))+\n  geom_line(linewidth = 1.2)+\n  theme_minimal()+\n  theme(legend.position = \"bottom\",legend.text = element_text(size = 5))+\n  labs(title = \"Party Seats by Year \", x = \"Year\", y= \"Number of Seats \", color = \"Party\")\n\n\n\n\n\n\n\n\n\n\n\n\nIn the state of New York, there is a fusion ticket system that allows for candidates to be put under more than one party line. This creates an interesting dynamic that allows for candidates to win even though they did not have the max number of votes in their respective parties. We see below that as a matter a fact, multiple times the candidate with the highest single party votes does not always win due to the fusion system.\n\n\nCode\nfusion &lt;- house_votes %&gt;% \n  filter(fusion_ticket == TRUE & candidate != \"BLANK\") %&gt;% \n  select(year,candidate,candidatevotes,district,party,totalvotes) %&gt;% \n  group_by(year,district,candidate) %&gt;% \n  mutate(total_fusion_votes =sum(candidatevotes)) %&gt;% \n  ungroup() %&gt;% \n  group_by(year,district) %&gt;% \n  mutate(highest_single_party_votes = candidate[which.max(candidatevotes)]) %&gt;% \n  ungroup()\n \nfusion_winners &lt;- fusion %&gt;%\n  group_by(year,district) %&gt;% \n  mutate(district_winner = candidate[which.max(total_fusion_votes)]) %&gt;%\n  select(year,district,district_winner,highest_single_party_votes) %&gt;% \n  filter(district_winner!=highest_single_party_votes) %&gt;% \n  distinct() %&gt;% \n  DT::datatable()\nfusion_winners\n\n\n\n\n\n\n\n\n\nHere we answer the question of whether or not there is a difference in votes in the congressional candidate and the presidential candidate of the same party. In this analysis I found certain cases where the congressional candidates had slightly more votes than the presidential, however the average difference across the years has actually been increasing.\n\n\nCode\nhouse_winners &lt;- house_votes %&gt;% \n  group_by(year,district,state,candidate) %&gt;% \n  mutate(cong_votes=sum(candidatevotes)) %&gt;% \n  ungroup %&gt;% group_by(year,district,state) %&gt;% \n  mutate(cong_winner = candidate[which.max(cong_votes)]) %&gt;% ungroup() %&gt;% \n  filter(cong_winner == candidate) %&gt;% \n  select(year,party,state,state_fips,district,cong_votes,cong_winner) %&gt;% \n  ungroup()\n\n \npres %&gt;% \n  inner_join(house_winners, by = c(\"state_fips\",\"party_detailed\" = \"party\",\"state\",\"year\")) %&gt;% \n  group_by(state,candidate,year,cong_winner) %&gt;% \n  mutate(vote_diff = candidatevotes - cong_votes) %&gt;% \n  ungroup() %&gt;% group_by(year) %&gt;%  \n  mutate(avg_diff = mean(vote_diff)) %&gt;% \n  select(year,state,state_fips,party_detailed,candidate,cong_winner,district,vote_diff,avg_diff) %&gt;% \n  ggplot(aes(x = year, y = avg_diff))+\n  geom_line(linewidth = 1.2, color = \"red\")+\n  theme_minimal()+\n  labs(title = \"Average Difference Between Congressional Candidate Votes & Presidential Votes\",\n       x = \"Year\", y = \"Average Difference\")\n\n\n\n\n\n\n\n\n\n\n\n\nWhen it is necessary to repeat a process over and over again it might be beneficial to create a function that is written once and can be used quickly again, or even automated. In this case we will make a function that can take any zip file, and receive its shape file. See below with a download and unzip along with a quick plot of the boroughs.\n\n\nCode\nlibrary(sf)\n\n\nWarning: package 'sf' was built under R version 4.3.3\n\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\n\nCode\nif(!file.exists(\"nyc_borough_boundaries.zip\")){\n    download.file(\"https://data.cityofnewyork.us/api/geospatial/tqmj-j8zm?method=export&format=Shapefile\", \n              destfile=\"nyc_borough_boundaries.zip\")\n}\n\n##-\nunzip_shape &lt;- function(filename){\n \n  dest_dir &lt;- tempdir()\n  file &lt;- unzip(zipfile = filename,exdir = dest_dir)\n  shp_file &lt;- file[grepl(\"\\\\.shp$\",file)]\n  sf &lt;- read_sf(shp_file)\n  return(sf)\n}\n### UNZIPPIING AND PLOTTING\nnyc_sf &lt;- unzip_shape(\"nyc_borough_boundaries.zip\")\n\nggplot(nyc_sf,\n       aes(geometry=geometry,\n           fill = shape_area)) +\n    geom_sf()+\n  theme_void()\n\n\n\n\n\n\n\n\n\n\n\n\nUsing some of the methods previously stated and a new method I will introduce shortly we can plot the US election of 2000, which many consider to be a very controversial election.\nThis new method involves using a cowplot that allows us to ggdraw multiple different plots over each other. This will be very beneficial when plotting the US because the geographic locations of Hawaii and Alaska make a simple plot extremely ugly. This process involves filtering out the 2 states and creating a “main” plot as seen in the code below, and then plotting those 2 states separately. Once this is done we can use the ggdraw function to join them all together and tinker with the x, y, width, and height to get a nice looking plot (note: 0 is the center)\n\n\nCode\nlibrary(tools)\nbushVgore &lt;- unzip_shape(\"tl_2023_us_state.zip\")\n\n# ggplot(bushVgore, \n#        aes(geometry=geometry)) + \n#     geom_sf()\n\nbushVgore &lt;- bushVgore %&gt;% select(NAME,geometry)\n\nelection_2000 &lt;- pres %&gt;% \n  filter(year == 2000 & candidate == \"BUSH, GEORGE W.\"| candidate==\"GORE, AL\") %&gt;% \n  mutate(state = toTitleCase(tolower(state))) %&gt;% \n  select(state,state_po,candidate,candidatevotes,state_fips,totalvotes) %&gt;% \n  inner_join(bushVgore, by = c(\"state\"=\"NAME\")) %&gt;% \n  group_by(state) %&gt;% \n  mutate(state_winner = candidate[which.max(candidatevotes)])\ncolor &lt;- c(\"BUSH, GEORGE W.\" = \"red\",\"GORE, AL\"=\"blue\")\nmain_land &lt;- election_2000 %&gt;% \n  filter(!state %in% c(\"Hawaii\", \"Alaska\")) %&gt;% \n  ggplot(aes(geometry = geometry, fill = state_winner)) +\n  scale_fill_manual(values = color) + \n  geom_sf() +\n  labs(fill = \"Candidate\") + \n  geom_sf_text(aes(label = state_po), size = 1, color = \"white\",fontface = \"bold\")+\n  theme_void()\n#main_land\n\nhawaii &lt;- election_2000 %&gt;% filter(state == \"Hawaii\") %&gt;% \n  ggplot(aes(geometry = geometry,fill = state_winner))+\n  scale_fill_manual(values = color)+\n  geom_sf()+\n  labs(fill = \"Candidate\") +\n   coord_sf(crs = st_crs(4326)) +\n  theme_void()+\n  geom_sf_text(aes(label = state_po), size = 1, color = \"white\",fontface = \"bold\")+\n  theme(legend.position = \"FALSE\")\n#hawaii\n\nalaska &lt;- election_2000 %&gt;%  filter(state ==\"Alaska\") %&gt;% \n  ggplot(aes(geometry = geometry,fill = state_winner))+\n  scale_fill_manual(values = color)+\n  geom_sf()+\n  labs(fill = \"Candidate\") +\n    coord_sf(crs = st_crs(4326)) +\n  theme_void()+\n  geom_sf_text(aes(label = state_po), size = 2, color = \"white\",fontface = \"bold\")+\n  theme(legend.position = \"FALSE\")\n#alaska\n\n# library(parallel)\n# options(mc.cores = NULL)\n\nlibrary(cowplot)\n\n\n\nAttaching package: 'cowplot'\n\n\nThe following object is masked from 'package:ggthemes':\n\n    theme_map\n\n\nThe following object is masked from 'package:lubridate':\n\n    stamp\n\n\nCode\nlibrary(gganimate)\nggdraw()+\n  draw_plot(main_land)+\n  draw_plot(hawaii, x= .1,width = 0.15, height = 0.15)+\n  draw_plot(alaska,y = -.25)\n\n\n\n\n\n\n\n\n\n\n\n\nIn this task we can use the tmap package to create an animated plot of party changes across time. For simplicity sake I have left out the 2 states previously mentioned (my apologizes to the Alaskans and Hawaiians).\n\n\nCode\nlibrary(tools)\nparties &lt;- pres %&gt;%\n  mutate(state = toTitleCase(tolower(state))) %&gt;% \n  filter(state !=\"Hawaii\" & state != \"Alaska\" & year &gt;= 2008) %&gt;% \n  inner_join(bushVgore, by = c(\"state\"=\"NAME\")) %&gt;% #bushvgore is the shape file\n  group_by(state,year) %&gt;%\n  mutate(state_winner = party_detailed[which.max(candidatevotes)]) %&gt;%\n  ungroup()\n\n### facetmap\nlibrary(tmap)\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nCode\n###ANIMATING THE FACET\nanim &lt;- parties %&gt;% \n  filter(year &gt;= 2000) %&gt;% \n  st_as_sf() %&gt;% \n  tm_shape() +\n  tm_polygons(\"state_winner\", title = \"Party\", \n              palette = c(\"REPUBLICAN\" = \"red\", \n                          \"DEMOCRAT\" = \"blue\",\n                          \"DEMOCRATIC-FARMER-LABOR\" = \"lightblue\")) +\n  tm_facets(along = \"year\", free.coords = FALSE)+\n  tm_text(\"state_po\", size = .3, col = \"white\", fontface = \"bold\")\n \n tmap_animation(anim, delay = 50,\"anim_map.gif\")\n\n\nCreating frames\n\n\n========================================\n\n\n====================\n\n\n====================\n\n\n\nCreating animation\nAnimation saved to /Users/harry/R/Project_0/anim_map.gif \n\n\nCode\nknitr::include_graphics(\"anim_map.gif\")"
  }
]