---
title: "Groups Most Affected by Unemployment"
author: "Harry Sohal"
editor: visual
code-fold: true
cache: true
---

## What Demographic Groups are Most Impacted by Unemployment?

In this section, I will delve into the demographic groups most impacted by unemployment, drawing connections to the broader unemployment landscape in New York. Specifically, I will examine key demographic categories such as Race and Educational Attainment while investigating potential underlying factors that may serve as root causes influencing these variables. This analysis aims to uncover deeper insights into the socioeconomic dynamics shaping unemployment trends in the region.

### Gathering the Data:

The first step in any analysis will be to gather some data that is reliable and obviously allows us to study the topic of interest. There are many sources of data that could be used, here but for the first part of this analysis I will use a dataset from kaggle that contains Unemployment by Demographic and Year. This data set can be found [here](https://www.kaggle.com/datasets/aniruddhasshirahatti/us-unemployment-dataset-2010-2020). The choice for this data mainly revolved around the fact that it all the variable needed to study this topic, without having to search and merge multiple different sources. Some other sources like the Census will be used in later sections.

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(httr)
library(jsonlite)
library(dplyr)
library(tidyverse,ggplot2)
library(janitor)
library(tidygeocoder)
library(tools)
library(leaflet)
library(tmap)
library(sf)
library(RColorBrewer)
library(tidycensus,tidyverse)
library(lubridate)
library(gganimate)
census_api_key(readLines("census_key.txt"))

```

### Loading the Data:

```{r,load data,message=FALSE}
by_demo <- read_csv("unemployment_data_us.csv") %>% 
  mutate(Date = my(Date)) %>% 
  select(-Month,-Year) %>% 
  drop_na()

```

Now that the data is loaded to understand the relationship between demographics and unemployment we need to transform the data in to a long format so that it allows us to quickly plot and analyze each group using grouping methods.

```{r,long}
demo_long <- by_demo %>%
  pivot_longer(cols = -Date,
               names_to = "demographic",
               values_to = "unemployment_rate")

```

Now that we have the data in the correct format lets initialize some demographic types in variables that will allow us to separate the demographics into wider groups like race in education so that we can analyze these groups efficiently.

```{r, init demo variables}
race <- c("Asian","Black","Hispanic","White")
gender <-c("Men","Women")
education <- c("High_School","Primary_School","Professional_Degree","Associates_Degree")
```

Now we can see what these variables look like over time. Lets start with Race.

```{r, race anim}
race_anim<-demo_long %>%
  filter(demographic %in% race) %>%
  ggplot(aes(x = Date, y = unemployment_rate, color = demographic)) +
  geom_point()+
  theme_minimal()+
  transition_time(Date)+
  shadow_mark()+
  labs(y = "Unemploment Rate",x = "Date", color = "Race")+
  ggtitle("Unemployment by Race: {frame_time}")
race_anim
```

As you can see there is an overall decrease in Unemployment over time with a slight hint at upward movement at the year 2020 (COVID -19 bump). We can also see that there are certain races that start, and stay higher all the way to the end of the timeline. Specifically the Black group, with the Hispanic group underneath it but still higher than the rest. Another interesting point from this graphic is how straight and narrow the line for White race is, especially when compared to spread of the other groups which seem to form a thick band. Lets take a look at the spread numerically.

```{r, race sd}
Euclidean_Dist <- function(x, y) {
  sqrt((as.numeric(x) - as.numeric(lead(x)))^2 + (y - lead(y))^2)
}

# Apply this function across the entire 'Date' and 'unemployment_rate' columns
demo_long %>% 
  filter(demographic %in% race) %>%
  group_by(demographic) %>% 
  mutate(
    Euclidean_Distances = Euclidean_Dist(Date, unemployment_rate)
  ) %>%
  summarise("Average Euclidean Distance" = mean(Euclidean_Distances, na.rm = TRUE)) %>%
  rename(Race = demographic) %>% 
  arrange(desc("Average Euclidean Distance")) %>% 
  DT::datatable()

```

Looks like there all about the same, but it does some difference that corresponds with the spread on the plot.Now lets look at some other variables. Below we have gender variable.

```{r,gender}
gender_anim <-demo_long %>%
  filter(demographic %in% gender) %>%
  ggplot(aes(x = Date, y = unemployment_rate, color = demographic)) +
  geom_point()+
  theme_minimal()+
  transition_time(Date)+
  shadow_mark()+# shadow mark allows the dots to stay on the plot in stead of disappering and looking stupid
  labs(y = "Unemploment Rate",x = "Date", color = "Gender")+
  ggtitle("Unemployment by Gender: {frame_time}")

gender_anim
```

As you can see from this plot the Male scatter starts at a higher intercept and converges into the same scatter. This is an interesting output as one would conventionally assume that women would face more adversity in the workplace.

Next we look at the education variable:

```{r, education anim}
education_anim <- demo_long %>%
  filter(demographic %in% education) %>%
  ggplot(aes(x = Date, y = unemployment_rate, color = demographic)) +
  geom_point()+
  theme_minimal()+
  transition_time(Date)+
  shadow_mark()+
  labs(y = "Unemploment Rate",x = "Date", color = "Education")+
  ggtitle("Unemployment by Education: {frame_time}")
education_anim
```

Here we see interestingly, that as expected the lower education groups have a higher unemployment, but as the time goes on they get closer and closer. While this shows us that unemployment is still quite different among educational groups, we see that over the time the difference might be fading, indicating that there might be more opportunities now for people with less educational attainment.

Next well look at the averages of all the groups side by side.

```{r, demo bar }

my_theme <- theme_minimal()+
  theme(axis.title.x = element_text(face = "bold", size = 9),  
    axis.title.y = element_text(face = "bold", size = 9))


avg_rate <- demo_long %>% group_by(demographic) %>% reframe(Average = mean(unemployment_rate))
avg_rate %>% 
  ggplot(aes(x = demographic, y = Average))+
  geom_bar(stat = "identity",color = "blue",fill = "lightblue")+
  my_theme+
  theme(axis.text.x = element_text(angle = 90))

```

We see above that Race, in this case black, and Education (primary school) have the highest average unemployment rate. The fact that these two are the highest leads me to believe that their might be a correlation here and perhaps, education is the true underlying factor here that is driving these other groups to have higher levels of unemployment. Lets compare some more data to see the overlap.

### Exploring the Census Variables

The Census has a vast amount of information across many different demographic groups economic factors. To search for the variables we will need to use the load variables feature to see all of the variables that the census offers and filter for the ones that we need. This will be done using `filter` in combination with `grepl`.

```{r}
#load the variables 
acs_vars <- load_variables(2022, "acs5", cache = TRUE)
#filter for demographics
acs_dt <-acs_vars %>% 
  filter(grepl("C15002",name) & grepl(".*Bachelor.*", label, ignore.case = TRUE))%>%
  DT::datatable()
acs_dt
```

Now this allows us to see all the variables we are interested in filtering for the first part of the education code and the filtering further for only bachelors degrees. Now we can get the data for the groups we are interested in. Here I will look at the number of men in each race with at least a bachelors degree. After obtaining that we can we filter down the for the boroughs, and make a proportion of at least a bachelors degree using the races respective total population.

First we can initialize the counties we need to filter for. Later on to filter, we will use the `grepl` function and the "or" operator. In this case the simple filter and `%in%` method doesn't work here so we'll use this more dynamic `grepl` method shown below. Now we can get the data from census and apply the pipeline.

```{r, census data and bachelor filter,message=FALSE}
#GETTING DATA

borroughs <-c(
"Kings County",
"Bronx County",
"New York County",
"Queens County",
'Richmond County')

census_api_key(readLines("census_key.txt"))
year = "2023"
edu_black <- get_acs(
  geography = "county",
  state = "NY",
  variables = "C15002B_006",
  year =  year ,
  survey = "acs1")

edu_white <- get_acs(
  geography = "county",
  state = "NY",
  variables = "C15002A_006",
  year =  year ,
  survey = "acs1")

edu_latino <- get_acs(
  geography = "county",
  state = "NY",
  variables = "C15002I_006",
  year =  year ,
  survey = "acs1")

#START THE PIPLINING  
edu_latino_total <- edu_latino %>%
  mutate(County = sub(", .*", "", NAME)) %>%# get into county only format
  drop_na() %>%  
  filter(grepl(paste(borroughs, collapse = "|"),County)) %>% #use county list to filter 
  summarise(Latino = sum(estimate)/2.4e6)
 
 edu_white_total <- edu_white %>% 
   drop_na() %>%  
  mutate(County= sub(", .*","",NAME)) %>% 
   drop_na() %>% 
   filter(grepl(paste(borroughs, collapse = "|"),County)) %>% 
   summarise(White= sum(estimate)/2.8e6)
 
 edu_black_total <- edu_black %>% 
   drop_na() %>%
   mutate(County= sub(", .*","",NAME)) %>% 
   drop_na() %>% 
   filter(grepl(paste(borroughs, collapse = "|"),County)) %>% 
   summarise(Black = sum(estimate)/1.8e6)

bach_edu_pop <- bind_cols(edu_latino_total, edu_white_total, edu_black_total)

bach_edu_pop <- bach_edu_pop %>%
  pivot_longer(
    cols = everything(), 
    names_to = "Group",   
    values_to = "Total")
```

Now we can plot the results.

```{r, bachelors plot}

bach_edu_pop %>% 
  ggplot(aes(x = Group, y = Total))+
  geom_bar(stat = "identity",color = "blue",fill = "lightblue")+
  my_theme+
  labs(y = "Proportion")
```

You can see that the black and then Latino group is significantly lower the than the White group. This aligns well with the unemployment by race as Black and Latino were the top 2 highest unemployment see above, however black is slightly higher than Latino which was unexpected. Let's see how this comparison looks geographically.

### Geographic Comparison of Race and Education

Similarly from the last section we need to use the census api to get the data. In this section we will get the data for Less than High School Graduates and also get the total population data for that we can create a proportion. This way when we create a plot it will not be skewed by the larger populations likely having larger number of high school drop outs.

```{r,less hs map,message=FALSE,warning=FALSE}
year = "2023"
#get less than highschool data
less_hs_by_geo <- get_acs(
  geography = "county",
  state = "NY",
  variables = "B06009_002",
  year =  year ,
  survey = "acs1")

# number of less than highschool level education by geography
less_HS_GEO <-less_hs_by_geo %>%
  mutate(County= sub(", .*","",NAME)) %>% 
  select(-NAME) %>% 
  filter(grepl(paste(borroughs, collapse = "|"),County))

### get the shape file and join for plotting
library(sf)
borrough_shape <-read_sf("nyc_borough_boundaries/geo_export_1b7449ee-3559-48e8-b506-c4147ebf3d4d.shx") %>% 
  arrange(boro_name)#arrange will allow us to just stack since both are in Alphabetical order

less_HS_GEO <- less_HS_GEO %>% bind_cols(borrough_shape)

# get the total population so that we can do a proportion, and not have the population size effect our results
total_population <- get_acs(
  geography = "county",
  state = "NY",
  variables = "B01003_001",
  year = year,
  survey = "acs1")
# apply the pipeline to get our counties to the population data
less_HS_PROP <- total_population %>%
  mutate(County= sub(", .*","",NAME)) %>% 
  rename(total_pop = estimate) %>% 
  select(-NAME,-GEOID,-moe,-variable) %>% 
  inner_join(less_HS_GEO,by = "County") %>%
  mutate(prop = estimate/total_pop)#
#less_HS_PROP


less_hs<-ggplot(less_HS_PROP, aes(geometry = geometry, fill = prop))+
  geom_sf()+
  geom_sf_text(aes(label = boro_name), size = 2, color = "black",fontface = "bold")+
  scale_fill_gradient(low = "white", high = "red") +
  labs(fill = "Proportion of Less then HS Education",title = "Less than High School Degree Attained by Borrough")+
  theme_void()+
  theme(legend.position = "bottom",plot.title = element_text(hjust = 0.5,face = "bold.italic",size = 12))

##plot the black population
black_population <- get_acs(
  geography = "county",
  state = "NY",
  variables = "B01001B_001",
  year = year,
  survey = "acs1")

black_population<- black_population %>% 
  mutate(County= sub(", .*","",NAME)) %>% 
  select(-NAME) %>% 
  filter(grepl(paste(borroughs, collapse = "|"),County)) %>% 
  arrange(County) %>%
  bind_cols(borrough_shape)
  
black_pop<-ggplot(less_HS_PROP, aes(geometry = geometry, fill = estimate))+
  geom_sf()+
  geom_sf_text(aes(label = boro_name), size = 2, color = "black",fontface = "bold")+
  scale_fill_gradient(low = "white", high = "red") +
  labs(fill = "Population Esitmate",title = "Black Population in NY Boroughs")+
  theme_void()+
  theme(legend.position = "FALSE",plot.title = element_text(hjust = 0.5,face = "bold.italic",size = 12))

```

```{r,cowplot,warning=FALSE}
library(cowplot)
black_pop_less_hs_pop <- plot_grid(black_pop, less_hs, ncol = 1,nrow = 2)
black_pop_less_hs_pop
```

We can see that there are is a good amount of overlap here with the black population and portion of lower education. We can also build a regression model to see which groups are contribute to the unemployment the most.

### Regression Analysis

In this section I'll aim to build a model, with my build off the model with my colleague, Miguel Tola, to see if we can quantify the relationship between the the predictor variables and unemployment. For this we will need some extra data, and curtsy of Miguel, we can use loops to automate this data pulling from the API's. After looping through tall the information we need this data will be joined into one unified table to study the regression analysis.

```{r,api loops, message=FALSE}
###FROM MIGUEL ####
# Initialize data frame
ny_male_population_df <- data.frame()

# Loop through years
for (year in 2005:2019) {
  # Retrieve data
  male_population <- get_acs(
    geography = "state",
    state = "NY",
    variables = "B03002_002",
    year = year,
    survey = "acs1"
  )
  
  # Check for errors
  if (nrow(male_population) > 0) {
    # Add year column
    male_population$year <- year
    
    # Bind rows to data frame
    ny_male_population_df <- bind_rows(ny_male_population_df, male_population)
  } else {
    print(paste("No data available for", year))
  }
}

# Initialize data frame
ny_female_population_df <- data.frame()

# Loop through years
for (year in 2005:2019) {
  # Retrieve data
  female_population <- get_acs(
    geography = "state",
    state = "NY",
    variables = "B03002_003",
    year = year,
    survey = "acs1"
  )
  
  # Check for errors
  if (nrow(female_population) > 0) {
    # Add year column
    female_population$year <- year
    
    # Bind rows to data frame
    ny_female_population_df <- bind_rows(ny_female_population_df, female_population)
  } else {
    print(paste("No data available for", year))
  }
}

glimpse(ny_female_population_df)

# Initialize data frame
ny_white_population_df <- data.frame()

# Loop through years
for (year in 2005:2019) {
  # Retrieve data
  white_population <- get_acs(
    geography = "state",
    state = "NY",
    variables = "B02001_002",
    year = year,
    survey = "acs1"
  )
  
  # Check for errors
  if (nrow(white_population) > 0) {
    # Add year column
    white_population$year <- year
    
    # Bind rows to data frame
    ny_white_population_df <- bind_rows(ny_white_population_df, white_population)
  } else {
    print(paste("No data available for", year))
  }
}

# Initialize data frame
ny_black_population_df <- data.frame()

# Loop through years
for (year in 2005:2019) {
  # Retrieve data
  black_population <- get_acs(
    geography = "state",
    state = "NY",
    variables = "B02001_002",
    year = year,
    survey = "acs1"
  )
  
  # Check for errors
  if (nrow(black_population) > 0) {
    # Add year column
    black_population$year <- year
    
    # Bind rows to data frame
    ny_black_population_df <- bind_rows(ny_black_population_df, black_population)
  } else {
    print(paste("No data available for", year))
  }
}

# Initialize data frame
ny_hispanic_population_df <- data.frame()

# Loop through years
for (year in 2005:2019) {
  # Retrieve data
  hispanic_population <- get_acs(
    geography = "state",
    state = "NY",
    variables = "B03001_001",
    year = year,
    survey = "acs1"
  )
  
  # Check for errors
  if (nrow(hispanic_population) > 0) {
    # Add year column
    hispanic_population$year <- year
    
    # Bind rows to data frame
    ny_hispanic_population_df <- bind_rows(ny_hispanic_population_df, hispanic_population)
  } else {
    print(paste("No data available for", year))
  }
}

# Initialize data frame
ny_black_population_df <- data.frame()

# Loop through years
for (year in 2005:2019) {
  # Retrieve data
  black_population <- get_acs(
    geography = "state",
    state = "NY",
    variables = "B02001_002",
    year = year,
    survey = "acs1"
  )
  
  # Check for errors
  if (nrow(black_population) > 0) {
    # Add year column
    black_population$year <- year
    
    # Bind rows to data frame
    ny_black_population_df <- bind_rows(ny_black_population_df, black_population)
  } else {
    print(paste("No data available for", year))
  }
}

# Initialize data frame
ny_asian_population_df <- data.frame()

# Loop through years
for (year in 2005:2019) {
  # Retrieve data
  asian_population <- get_acs(
    geography = "state",
    state = "NY",
    variables = "B01001D_001",
    year = year,
    survey = "acs1"
  )
  
  # Check for errors
  if (nrow(asian_population) > 0) {
    # Add year column
    asian_population$year <- year
    
    # Bind rows to data frame
    ny_asian_population_df <- bind_rows(ny_asian_population_df, asian_population)
  } else {
    print(paste("No data available for", year))
  }
}

# Initialize data frame
less_than_hs_population_df <- data.frame()

# Loop through years
for (year in 2005:2019) {
  # Retrieve data
  less_than_hs_population <- get_acs(
    geography = "state",
    state = "NY",
    variables = "B06009_002",
    year = year,
    survey = "acs1"
  )
  
  # Check for errors
  if (nrow(less_than_hs_population) > 0) {
    # Add year column
    less_than_hs_population$year <- year
    
    # Bind rows to data frame
    less_than_hs_population_df <- bind_rows(less_than_hs_population_df, less_than_hs_population)
  } else {
    print(paste("No data available for", year))
  }
}

# Initialize data frame
hs_population_df <- data.frame()

# Loop through years
for (year in 2005:2019) {
  # Retrieve data
  hs_population <- get_acs(
    geography = "state",
    state = "NY",
    variables = "B06009_003",
    year = year,
    survey = "acs1"
  )
  
  # Check for errors
  if (nrow(hs_population) > 0) {
    # Add year column
    hs_population$year <- year
    
    # Bind rows to data frame
    hs_population_df <- bind_rows(hs_population_df, hs_population)
  } else {
    print(paste("No data available for", year))
  }
}

#some college or associates degree
# Initialize data frame
some_college_population_df <- data.frame()

# Loop through years
for (year in 2005:2019) {
  # Retrieve data
  some_college_population <- get_acs(
    geography = "state",
    state = "NY",
    variables = "B06009_004",
    year = year,
    survey = "acs1"
  )
  
  # Check for errors
  if (nrow(some_college_population) > 0) {
    # Add year column
    some_college_population$year <- year
    
    # Bind rows to data frame
    some_college_population_df <- bind_rows(some_college_population_df, some_college_population)
  } else {
    print(paste("No data available for", year))
  }
}

# Initialize data frame
bachelors_population_df <- data.frame()

# Loop through years
for (year in 2005:2019) {
  # Retrieve data
  bachelors_population <- get_acs(
    geography = "state",
    state = "NY",
    variables = "B06009_005",
    year = year,
    survey = "acs1"
  )
  
  # Check for errors
  if (nrow(bachelors_population) > 0) {
    # Add year column
    bachelors_population$year <- year
    
    # Bind rows to data frame
    bachelors_population_df <- bind_rows(bachelors_population_df, bachelors_population)
  } else {
    print(paste("No data available for", year))
  }
}

#Graduate or professional degree 
# Initialize data frame

graduate_population_df <- data.frame()

# Loop through years
for (year in 2005:2019) {
  # Retrieve data
  graduate_population <- get_acs(
    geography = "state",
    state = "NY",
    variables = "B06009_005",
    year = year,
    survey = "acs1"
  )
  
  # Check for errors
  if (nrow(graduate_population) > 0) {
    # Add year column
    graduate_population$year <- year
    
    # Bind rows to data frame
    graduate_population_df <- bind_rows(graduate_population_df, graduate_population)
  } else {
    print(paste("No data available for", year))
  }
}
#Creating a table for the regression model
library(fredr)
fredr_set_key(read_lines("FRED_key.txt"))

ny_unrate <- fredr(
  series_id = "NYUR",
  observation_start = as.Date("2005-01-01"),
  observation_end = as.Date("2019-12-31"),
  frequency = "a"  # monthly
)

ny_unrate$year <- as.integer(format(ny_unrate$date, "%Y"))


regression_model_table <- ny_unrate |>
  left_join(ny_female_population_df |>
              select(female_pop = estimate, year), join_by(year == year)) |>
  select(-date)



regression_model_table <- ny_unrate |>
  select(year, unemployment_rate = value) |>
  left_join(ny_female_population_df |>
              select(female_pop = estimate, year), 
            by = "year") |>
  left_join(ny_male_population_df |>
              select(male_pop = estimate, year),
            by = "year") |>
  left_join(less_than_hs_population_df |>
              select(less_than_hs_pop = estimate, year),
            by = "year") |>
  left_join(hs_population_df |>
              select(hs_pop = estimate, year),
            by = "year") |>
  left_join(some_college_population_df |>
              select(some_college_pop = estimate, year),
            by = "year") |>
  left_join(bachelors_population_df |>
              select(bachelors_pop = estimate, year),
            by = "year") |>
  left_join(graduate_population_df |>
              select(graduate_pop = estimate, year),
            by = "year") |>
  left_join(ny_asian_population_df |>
              select(ny_asian_pop = estimate, year),
            by = "year") |>
  left_join(ny_white_population_df |>
              select(ny_white_pop = estimate, year),
            by = "year") |>
  left_join(ny_black_population_df |>
              select(ny_black_pop = estimate, year),
            by = "year") |>
  left_join(ny_hispanic_population_df |>
              select(ny_hispanic_pop = estimate, year),
            by = "year")

```

Now that we have our data we can begin some analysis and then building our model. This first model that we'll examine is built by Miguel.

```{r, miguels model}
miguels_model <- lm(unemployment_rate ~ 
                        female_pop + 
                        male_pop + 
                        less_than_hs_pop + 
                        hs_pop + 
                        some_college_pop + 
                        bachelors_pop + 
                        
                        ny_asian_pop + 
                        ny_white_pop + 
                        
                        ny_hispanic_pop,
                      data = regression_model_table)
summary(miguels_model)
```

So as you can see the model as a whole does have some good numbers, is mostly likely able to predict fairly well, and has good explain-ability with an R-squared Adjusted of .88. However, in my case I would like to understand the underlying nature of demographic groups and see whether or not my previous findings hold up. For this I will need more statistical significance in the individual variables. To see why these variables have such high p-values lets start by visualizing some of the points.

```{r, first regression plot}

grad_point <-regression_model_table %>% 
  select(-year) %>%
  ggplot(aes(x = graduate_pop,y = unemployment_rate))+
  geom_point(color  = "red")+
  my_theme+
  labs(y = "")
  
hs_point <- regression_model_table %>% 
  select(-year) %>% 
  ggplot(aes(x = hs_pop, y = unemployment_rate))+
  geom_point(color = "green")+
  my_theme+
  labs(y = "")
black_point <- regression_model_table %>% 
  select(-year) %>% 
  ggplot(aes(x = ny_black_pop,y = unemployment_rate))+
  geom_point(color = "blue")+
  my_theme+
  labs(y = "")
trend_point <- regression_model_table %>% 
  ggplot(aes(x = year, y = unemployment_rate))+
  geom_point(color = "darkred")+
  my_theme+
  labs(y = "")


trend_grid<- plot_grid(grad_point,
                           hs_point,
                           black_point,
                           trend_point,
                           ncol = 2,nrow = 2)

trend_analysis <- ggdraw() +
  draw_label("Unemployment Rate", 
             x = 0.04, 
             y = 0.5, 
             angle = 90, 
             vjust = 1,
             fontface = "bold") + 
  draw_plot(trend_grid, x = 0.05, y = 0, width = 0.95, height = 1) 

trend_analysis
```

As you can see the above the grid plot, there are similarities between all of the demographic groups that I have selected, and it almost exactly matches the the unemployment by year suggesting that time is significantly impacting the unemployment rate. This makes sense as we know that certain time periods had high unemployment rates due to the economic factors of the time period that are not in the scope of this analysis. For example after the crash in 2008 we can see a large spike in unemployment. This trend is seen across the variables explored above. The question becomes how can be be sure what demographic groups in this study are actually affect unemployment?

### Detrending Data

After realizing that time was significantly impacting our results, particularly time periods of economic downturns, the first procedure we will look at is to simply remove those data points. Before doing so I will take a slightly different approach to my colleague Miguel and use proportions instead of total numbers.

```{r,remove time}
library(dplyr)
### creating a proportions for the data instead of actual estimates

regression_prop <- regression_model_table %>%
  group_by(year) %>%
  mutate(
    total_pop_yr = rowSums(across(c(female_pop, male_pop, less_than_hs_pop, 
                                    hs_pop, some_college_pop, bachelors_pop, 
                                    graduate_pop, ny_asian_pop, ny_white_pop, 
                                    ny_black_pop, ny_hispanic_pop))),
    across(c(female_pop, male_pop, less_than_hs_pop, hs_pop, 
             some_college_pop, bachelors_pop, graduate_pop, 
             ny_asian_pop, ny_white_pop, ny_black_pop, 
             ny_hispanic_pop), ~ .x / total_pop_yr, .names = "{.col}_prop")) %>%
  select(year, unemployment_rate, ends_with("_prop")) %>%
  ungroup()

prop_df <- regression_prop %>% 
  arrange(desc(unemployment_rate)) %>% 
    slice(-(1:5))

prop_df%>%
  ggplot(aes(x = graduate_pop_prop,y =  unemployment_rate))+
  geom_point()+
  my_theme
```

Above we see this doesn't really remove the trend as hoped. In order to get the results desired a more formal detrending technique will be needed. For this we will first build a model with the trend component (time) and unemployment. After regressing the unemployment on time we will obtain the residuals and regress the new model on these squared errors. This is essentially modeling the variability in the model with time, and using the other predictors to then explain this variability.

```{r,residual model}
model <- lm(unemployment_rate ~ year, data = regression_prop)
#using the residuals as a form of detrending 

detrend_df <- regression_prop %>%
  mutate(detrended_unemployment_rate = exp(residuals(model)))
hs_detrend<-detrend_df %>% 
  ggplot(aes(x = less_than_hs_pop_prop,y =  detrended_unemployment_rate))+
  geom_point()+
  labs(y = "", x = "Less Than High School Proportion")+
   geom_smooth(method = "loess", se = TRUE, color = "blue")+
  my_theme
grad_detrend<-detrend_df %>% 
  ggplot(aes(x = graduate_pop_prop,y =  detrended_unemployment_rate))+
  geom_point()+
  labs(y = "", x = "Graduate School Proportion")+
   geom_smooth(method = "loess", se = TRUE, color = "blue")+
  my_theme
detrend_grid <- plot_grid(hs_detrend,grad_detrend, nrow = 2)

detrend_analysis <- ggdraw() +
  draw_label("Detrended Unemployment Rate", 
             x = 0.04, 
             y = 0.5, 
             angle = 90, 
             vjust = 1,
             fontface = "bold") + 
  draw_plot(detrend_grid, x = 0.05, y = 0, width = 0.95, height = 1) 
detrend_analysis
```

It seems like the trend isn't completely gone but it seems make more sense, peaking at different levels instead one single a peak at virtually the same spot. Now lets see if we can get some statistically significant results using a regression model with this detrended data. Based on the plot a second order model might be more appropriate here. The regression equation used is as follows where the first epsilon represents the error from the initial model:

$$
\Large\epsilon^2 = 
\Large\beta_0 + \beta_1 \small(\text{Less than HS Prop}) + \Large\beta_2 \small(\text{Less than HS Prop})^2 + \Large\beta_3 \small(\text{Grad Prop}) + \Large\beta_4 \small(\text{Grad Prop})^2 + \Large\epsilon'
$$

**Regression Output:**

```{r, summary model}
detrend_model <- lm(detrended_unemployment_rate ~ 
             less_than_hs_pop_prop + 
             I(less_than_hs_pop_prop^2) + 
             graduate_pop_prop+
             I(graduate_pop_prop^2),
             data = detrend_df)
summary(detrend_model)
```

**Detrended Model Visualized:**

Below is the three dimensional plane representing the model above. It shows the two education variables at various points and its corresponding predicted error. This prediction indicates how much the unemployment would change, and in which direction on top of the trend component in the separate model. This has some points that are unrealistic of course, like an Graduate level education proportion of 1 or of 0. These points are outside the scope of the fitted model thus don't provide accurate actual predictions but the regression surface still functions as a great visual of the nature of education and unemployment.

```{r,3d plane, message=FALSE}

less_than_hs_pop_prop <- seq(0, 1,length = 50)
graduate_pop_prop <- seq(0, 1,length = 50)


df <- expand.grid(less_than_hs_pop_prop = less_than_hs_pop_prop,
                    graduate_pop_prop = graduate_pop_prop)

df <- df %>% mutate(pred_residual = predict(detrend_model, newdata= df))

library(plotly)
axy <- list(
  title = "Grad"
)

axx <- list(
  title = "Less-HS"
)

axz <- list(
  title = "e^2"
)

regression_surface <- plot_ly(df, x = ~less_than_hs_pop_prop, 
        y = ~graduate_pop_prop, 
        z = ~pred_residual,
        type = 'scatter3d',
        marker = list(color = df$pred_residual)) %>% 
  layout(scene = list(xaxis=axx,yaxis=axy,zaxis=axz))

regression_surface
```

### Conclusion

In conclusion, the groups most affected by unemployment are those with lower levels of education. While it may initially appear that certain racial groups, such as the Black demographic, are disproportionately impacted due to their higher unemployment rates, a deeper analysis reveals that education is a confounding factor. The racial groups with the highest unemployment rates also tend to have lower levels of education, which contributes significantly to their unemployment status. We see that education is also a statistically significant predictor of unemployment, reinforcing the idea that individuals with lower educational attainment are the most vulnerable to unemployment.
